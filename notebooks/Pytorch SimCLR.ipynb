{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9fb144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ")\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import (\n",
    "    RandomResizedCrop,\n",
    "    RandomHorizontalFlip,\n",
    "    ColorJitter,\n",
    "    RandomGrayscale,\n",
    "    RandomApply,\n",
    "    Compose,\n",
    "    GaussianBlur,\n",
    "    ToTensor,\n",
    ")\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f13864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch-Version 1.12.0+cpu\n",
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f'Torch-Version {torch.__version__}')\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'DEVICE: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a7816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_transform(output_shape, kernel_size, s=1.0):\n",
    "    \"\"\"\n",
    "    The color distortion transform.\n",
    "    \n",
    "    Args:\n",
    "        s: Strength parameter.\n",
    "    \n",
    "    Returns:\n",
    "        A color distortion transform.\n",
    "    \"\"\"\n",
    "    rnd_crop = RandomResizedCrop(output_shape)\n",
    "    rnd_flip = RandomHorizontalFlip(p=0.5)\n",
    "    \n",
    "    color_jitter = ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "    rnd_color_jitter = RandomApply([color_jitter], p=0.8)\n",
    "    \n",
    "    rnd_gray = RandomGrayscale(p=0.2)\n",
    "    gaussian_blur = GaussianBlur(kernel_size=kernel_size)\n",
    "    rnd_gaussian_blur = RandomApply([gaussian_blur], p=0.5)\n",
    "    to_tensor = ToTensor()\n",
    "    image_transform = Compose([\n",
    "        to_tensor,\n",
    "        rnd_crop,\n",
    "        rnd_flip,\n",
    "        rnd_color_jitter,\n",
    "        rnd_gray,\n",
    "        rnd_gaussian_blur,\n",
    "    ])\n",
    "    return image_transform\n",
    "\n",
    "\n",
    "class ContrastiveLearningViewGenerator(object):\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform, n_views=2):\n",
    "        self.base_transform = base_transform\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        views = [self.base_transform(x) for i in range(self.n_views)]\n",
    "        return views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b54caa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Flowers Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, list_images, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            list_images (list): List of all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.list_images = list_images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        img_name = self.list_images[idx]\n",
    "        image = io.imread(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59693571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of the images\n",
    "output_shape = [224,224]\n",
    "kernel_size = [21,21] # 10% of the output_shape\n",
    "\n",
    "# The custom transform\n",
    "base_transforms = get_complete_transform(output_shape=output_shape, kernel_size=kernel_size, s=1.0)\n",
    "custom_transform = ContrastiveLearningViewGenerator(base_transform=base_transforms)\n",
    "\n",
    "flowers_ds = CustomDataset(\n",
    "    list_images=glob.glob(\"/kaggle/input/flowers-recognition/flowers/flowers/*/*.jpg\"),\n",
    "    transform=custom_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c49f23",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23240\\1707719599.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mview_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflowers_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23240\\1707719599.py\u001b[0m in \u001b[0;36mview_data\u001b[1;34m(flowers, index)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mview_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflowers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflowers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mview1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23240\\2416238644.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mimg_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "def view_data(flowers, index):\n",
    "    for i in range(1,6):\n",
    "        images = flowers[index]\n",
    "        view1, view2 = images\n",
    "        plt.subplot(5,2,2*i-1)\n",
    "        plt.imshow(view1.permute(1,2,0))\n",
    "        plt.subplot(5,2,2*i)\n",
    "        plt.imshow(view2.permute(1,2,0))\n",
    "\n",
    "view_data(flowers_ds,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f93b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
