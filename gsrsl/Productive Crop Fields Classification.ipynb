{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9799cd82",
   "metadata": {},
   "source": [
    "# Productive Crop Field Contrastive Learning SimCLR Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbfac48",
   "metadata": {},
   "source": [
    "The goal of this notebook is to evaluate the three different methods to predict whether an area is a productive field or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa809d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "[1. Data Processing](#data_processing)\n",
    "\n",
    "[2. Contrastive Learning (SimCLR)](#model_training)\n",
    "\n",
    "[3. Siamese with Triplet Loss](#siamese_triplet_loss)\n",
    "\n",
    "[4. Positive Unlabeled Learning](#pu_learning)\n",
    "\n",
    "[5. Results](#results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d094de",
   "metadata": {},
   "source": [
    "## Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d2abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Install packages required only once\n",
    "install_packages = False\n",
    "\n",
    "if install_packages:\n",
    "    !{sys.executable} -m pip install sklearn\n",
    "    !{sys.executable} -m pip install seaborn\n",
    "    !{sys.executable} -m pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed2098e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn.objects as so\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f75990c",
   "metadata": {},
   "source": [
    "## Hyper-parameters and other constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37af3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_samples = 15\n",
    "band_features = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']\n",
    "\n",
    "width = 30 # output vector size\n",
    "temperature = 0.5 # empirical temperature value\n",
    "\n",
    "steps_per_epoch = 10\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "shuffle_buffer = 5\n",
    "num_epochs = 20\n",
    "\n",
    "queue_size = 10000\n",
    "kernel_size = 3\n",
    "strides = 1\n",
    "\n",
    "# Stronger augmentations for contrastive, weaker ones for supervised training\n",
    "contrastive_augmentation = {\"jitter\": 0.3}\n",
    "classification_augmentation = {\"jitter\": 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc831752",
   "metadata": {},
   "source": [
    "<a id='data_processing'></a>\n",
    "\n",
    "# 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b28f63",
   "metadata": {},
   "source": [
    "## 1.1. Load all parquet files from the configured folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62df2f60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of loaded positive dataframe is: (100430, 14)\n",
      "The shape of loaded negative dataframe is: (40482, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hex</th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B08</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B09</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_p_0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>3258.0</td>\n",
       "      <td>3701.0</td>\n",
       "      <td>3692.0</td>\n",
       "      <td>3906.0</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>2627.0</td>\n",
       "      <td>1538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_p_1</td>\n",
       "      <td>527.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>3248.0</td>\n",
       "      <td>3616.0</td>\n",
       "      <td>3692.0</td>\n",
       "      <td>3899.0</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>1605.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_p_2</td>\n",
       "      <td>507.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>1663.0</td>\n",
       "      <td>3111.0</td>\n",
       "      <td>3434.0</td>\n",
       "      <td>3448.0</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>3892.0</td>\n",
       "      <td>3057.0</td>\n",
       "      <td>1963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_p_3</td>\n",
       "      <td>507.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>3111.0</td>\n",
       "      <td>3549.0</td>\n",
       "      <td>3536.0</td>\n",
       "      <td>3739.0</td>\n",
       "      <td>3892.0</td>\n",
       "      <td>3037.0</td>\n",
       "      <td>2001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_p_4</td>\n",
       "      <td>521.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>3168.0</td>\n",
       "      <td>3477.0</td>\n",
       "      <td>3528.0</td>\n",
       "      <td>3804.0</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>1876.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp      hex    B01    B02     B03    B04     B05     B06  \\\n",
       "0  20181029T170421  hex_p_0  527.0  556.0  1080.0  680.0  1532.0  3258.0   \n",
       "1  20181029T170421  hex_p_1  527.0  537.0  1060.0  672.0  1564.0  3248.0   \n",
       "2  20181029T170421  hex_p_2  507.0  625.0  1162.0  861.0  1663.0  3111.0   \n",
       "3  20181029T170421  hex_p_3  507.0  609.0  1112.0  814.0  1638.0  3111.0   \n",
       "4  20181029T170421  hex_p_4  521.0  594.0  1134.0  777.0  1650.0  3168.0   \n",
       "\n",
       "      B07     B08     B8A     B09     B11     B12  \n",
       "0  3701.0  3692.0  3906.0  3746.0  2627.0  1538.0  \n",
       "1  3616.0  3692.0  3899.0  3746.0  2668.0  1605.0  \n",
       "2  3434.0  3448.0  3760.0  3892.0  3057.0  1963.0  \n",
       "3  3549.0  3536.0  3739.0  3892.0  3037.0  2001.0  \n",
       "4  3477.0  3528.0  3804.0  3768.0  2937.0  1876.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hex</th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B08</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B09</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_n_0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>3277.0</td>\n",
       "      <td>3696.0</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>3844.0</td>\n",
       "      <td>3662.0</td>\n",
       "      <td>3317.0</td>\n",
       "      <td>2241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_n_1</td>\n",
       "      <td>888.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>2765.0</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>3662.0</td>\n",
       "      <td>2883.0</td>\n",
       "      <td>1914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_n_2</td>\n",
       "      <td>888.0</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>1903.0</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>3344.0</td>\n",
       "      <td>3124.0</td>\n",
       "      <td>3636.0</td>\n",
       "      <td>3662.0</td>\n",
       "      <td>3379.0</td>\n",
       "      <td>2425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_n_3</td>\n",
       "      <td>888.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>2738.0</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>3662.0</td>\n",
       "      <td>2916.0</td>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_n_4</td>\n",
       "      <td>760.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>3406.0</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>4232.0</td>\n",
       "      <td>4069.0</td>\n",
       "      <td>3958.0</td>\n",
       "      <td>3155.0</td>\n",
       "      <td>1978.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp      hex    B01     B02     B03     B04     B05     B06  \\\n",
       "0  20181029T170421  hex_n_0  888.0  1034.0  1458.0  1546.0  1956.0  3277.0   \n",
       "1  20181029T170421  hex_n_1  888.0   934.0  1272.0  1340.0  1669.0  2765.0   \n",
       "2  20181029T170421  hex_n_2  888.0  1042.0  1458.0  1552.0  1903.0  3050.0   \n",
       "3  20181029T170421  hex_n_3  888.0   956.0  1256.0  1370.0  1643.0  2492.0   \n",
       "4  20181029T170421  hex_n_4  760.0   916.0  1368.0  1090.0  1844.0  3406.0   \n",
       "\n",
       "      B07     B08     B8A     B09     B11     B12  \n",
       "0  3696.0  4004.0  3844.0  3662.0  3317.0  2241.0  \n",
       "1  3081.0  2800.0  3364.0  3662.0  2883.0  1914.0  \n",
       "2  3344.0  3124.0  3636.0  3662.0  3379.0  2425.0  \n",
       "3  2738.0  2832.0  3076.0  3662.0  2916.0  2007.0  \n",
       "4  3768.0  4232.0  4069.0  3958.0  3155.0  1978.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_positive = pd.read_parquet('df_p.parquet.gzip')\n",
    "df_negative = pd.read_parquet('df_n.parquet.gzip')\n",
    "\n",
    "print('The shape of loaded positive dataframe is:', df_positive.shape)\n",
    "print('The shape of loaded negative dataframe is:', df_negative.shape)\n",
    "\n",
    "display(df_positive.head(5))\n",
    "display(df_negative.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b7206c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this dataset there are  5066  different positive hexes\n",
      "In this dataset there are  2050  different negative hexes\n"
     ]
    }
   ],
   "source": [
    "print('In this dataset there are ', df_positive.hex.unique().size, ' different positive hexes')\n",
    "print('In this dataset there are ', df_negative.hex.unique().size, ' different negative hexes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2903f7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABb0AAAJRCAYAAABhmRqiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbKElEQVR4nO3debxV8/4/8PdpOqk0GaKMFSJD5pIhJDLXJVzDNU9xb66SLr5cQqguimSmSJm/UbhklkKTojKVCqF57lTn90e/9vfsM+6Tk2r1fD4eHo/9WXuttT97n72X1Wt91vuTlZubmxsAAAAAAJAA5dZ3BwAAAAAAoKwIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGJUyHTF3NzcWLUqd132ZaNQrlyWzwHY4DlWARsLxytgY+BYBWwsHK9IsnLlsiIrKyujdTMOvVetyo3ZsxetdaeSoEKFclGrVtWYP39xrFixan13B6BQjlXAxsLxCtgYOFYBGwvHK5Kudu2qUb58ZqG38iYAAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEqPC+u4AQElyc3Nj+fJl67sbG42VK8vF0qXlY9mypbFixar13R0SIjc3NyIisrKy1nNPSBLHK2Bj4FgF6SpVynZOCGzwhN7ABm/58mVxxRUXru9uAAAAbPL69Hk8srMrr+9uABRLeRMAAAAAABLDSG9go1J1l1Mjq5xDF/yZcletiEXfvBIRfoMAAJuivOeDABsD/2oFNipZ5SoI3GA98hsEAABgQ6e8CQAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHqXQm5ubuTm5q7vbgAAAAAAmwiZZOkJvTOUm5sbXbveHJ07d/YlAwAAAADWudzc3Ljzzn/HnXf+WyZZChXWdwc2FsuXL4tvvpmcely+fKX13CMAAAAAIMmWL18W3377f5lkdnbl9dyjjYOR3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiVFjfHdgYLVu2LMqXX7W+uwGbjGXLlq3vLgAAABD+fbYhW7myXCxdWj6WLVsaK1bIrZLCb27tCL0zlJubm3p81VWXrceewKYtNzc3stZ3JwAAADYheTORDh2uWI89gU1b3t8ixVPeBAAAAACAxDDSO0NZWf83trR3775RvnzF9dgb2LQsW7YsNZog728RAACAdS/vv8PuvbdPZGdnr8feUJQKFcpFzZpVY+7cRcqbJIhMZO0IvddCdnZ2lC9faX13AwAAAOBPlZ2dHdnZldd3NyhEhQrlonLlypGdvdJcdGzylDcBAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYlRY3x3YWFSqlB277LJbVKhQLipVyo6VK3PXd5cAAAAAgASrVCk7GjbcNfWYzAi9M5SVlRU33nhL1KpVNebOXRwRQm8AAAAAYN3JysqKLl1uTj0mM0LvUsjKyvLlAgAAAAD+NPLI0lPTGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASQ+gNAAAAAEBiCL0BAAAAAEgMoTcAAAAAAIkh9AYAAAAAIDGE3gAAAAAAJIbQGwAAAACAxBB6AwAAAACQGEJvAAAAAAASo8L67gBAaeSuWrG+uwCbnLy/O79BAIBNj3NAYGMj9AY2Kou+eWV9dwE2aX6DAAAAbOiUNwEAAAAAIDGM9AY2eJUqZUefPo+v725sNCpUKBc1a1aNuXMXxYoVq9Z3d0iI3NzciIjIyspazz0hSRyvgI2BYxWkq1Qpe313AaBEQm9gg5eVlRXZ2ZXXdzc2GhUqlIvKlStHdvbKKF/eP8yADZfjFbAxcKwCgI2P8iYAAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYmTl5ubmZrJibm5urFqV0aqJVr58uVi5ctX67gZAsRyrgI2F4xWwMXCsAjYWjlckWblyWZGVlZXRuhmH3gAAAAAAsKFT3gQAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYlRY3x3YkAwZMiSuueaaqFevXgwbNqzE9Z9//vm48cYbS/Uaw4cPj9q1a69tF4FNzG+//RYDBw6MTz75JH744YdYsGBBVKlSJbbddts4+OCD48wzz4z69etnvL/JkydH//79Y8SIEfHLL79EhQoVYtttt43mzZtHu3btokGDBuvw3QBJVVbHquHDh8f5559fqtd+4YUXYq+99lrLngObmmnTpsWAAQPi448/junTp8eKFSuiTp06sccee8TJJ58cLVq0iHLlMhsb5rwKWJfK4njl3IpNmdD7//vtt9+ia9eupdpm0qRJ66g3ABH9+/ePu+++O5YtW5a2fN68eTFv3ryYOHFi9OvXLy666KL45z//WeIJT9++feO+++6LlStXpi3/5ptv4ptvvolnnnkmrrnmmrjooovK/L0AyVWWx6qJEyeu6+4Cm7Ann3wyunfvHjk5OWnLp06dGlOnTo2hQ4fGfvvtF3fddVfssMMOxe7LeRWwLpXV8cq5FZsyoXdELFq0KK688sqYNWtWqbbLe/A45ZRTonLlyiVuk8k6AH379o2ePXum2lWqVIn9998/tt5665g7d2588cUXMXfu3Fi1alU88sgjMWfOnLj99tuL3N/DDz+ctr969erFvvvuGytXrozPPvssfv/998jJyYm77747ypcvX+rRAMCmqayPVXnPrVq2bBlbbLFFiX3IZB2Ahx9+OHr06JFq16xZMw466KCoVq1aTJs2Lb744otYtWpVjBo1Ks4555x44YUXYuutty5yX86rgHWlLI9Xzq3YlGXl5ubmru9OrE+zZ8+O9u3bx6hRo1LLMi1vcuCBB8b8+fOjcuXKMWrUqChfvvy67Cqwifjqq6+ibdu2sebwfOqpp8a//vWvqFGjRmqdpUuXRu/eveORRx5JLevZs2eccMIJBfb39ddfx1/+8pfUSKRrr702Lr744tRoy+XLl8d//vOfePzxxyMionz58vHKK6/Errvuus7eI7DxK+tjVcTqQQRr/nH24YcfFvkPOIDSmDBhQpx++umpc6FzzjknOnXqlDYg6ZtvvomrrroqpkyZEhERLVq0iL59+xbYl/MqYF0qy+NVhHMrNm2b9ESWEyZMiNNOOy0t8M7UjBkzYv78+RER0bBhQ4E3UGYeeOCBVIjUsmXLuOuuu9JCpIjVd4107Ngxzj333NSyXr16Fbq/nj17pp00XXrppWnlBSpVqhSdO3eOdu3aRUTEypUro3fv3mX6noDkKetjVU5OTnz33XcREVGrVi3/KAPKTN++fVPnQq1atYqbbrqpwB24u+yyS/Tp0ycqVqwYERHvv/9+fP/99wX25bwKWJfK8njl3IpN3SYZei9ZsiTuu+++OOuss2LGjBkREbHZZpuVah95bxFp1KhRmfYP2HQtWrQoPvjgg1S7Y8eOxa7/97//PXWy88MPPxQ42ZkxY0Z8+OGHERGRnZ0dV1xxRZH7uu6666JKlSoREfHf//631CWfgE1HWR+rIiK+++67VN1K51ZAWVmyZEnaXbzt27cvct369evHfvvtFxERubm5BQZHOa8C1qWyPF5FOLeCTS70njp1ahx33HHx4IMPpiZcql+/fvTp06dU+8k7ieVuu+1Wpn0ENl1ff/11LF++PCIitt9++9h5552LXb969eqxyy67pNr5g6R33303NRLzwAMPjC233LLIfW2++eZx2GGHRUTEqlWr4u23316r9wAkX1kfqyKcWwHrxuLFi+Pcc8+Nww47LBo3blxi8JP3XOn3339Pe855FbAuleXxKsK5FWxyE1n+8ssv8csvv0RERFZWVpx99tnRsWPHPzSJpStmQFmpWLFiHHPMMfHLL7/Edtttl9E2ecsrLVy4MO25L774IvX44IMPLnFf+++/f7z55psRETF8+PA444wzMuoDsGkp62NVhHMrYN3YYostonPnzhmvP3Xq1NTjbbbZJu0551XAulSWx6sI51awyYXea+y///5x/fXXx957771W2+e/YrZ06dL46KOP4quvvor58+dHzZo1o1GjRtG8efNSl04BNl377LNPqeo+Ll++PFWnLSIKjDj69ttvU4/r169f4v4aNGiQepz3OAeQV1kfqyIKnlvl5OTEiBEjYuzYsTFnzpzYfPPNo0GDBnH44YdH9erV/9gbACjE8OHDY/z48RGxek6CNSO113BeBWwoSjpeRTi3gk0u9K5bt270798/DjzwwLXex+LFi+PHH3+MiIjatWtH//7948knn0xNbJlXjRo1on379nHeeedFVlbWWr8mQGGGDh0aixcvjoiIcuXKRePGjdOenz59eupxvXr1Stxf3hECP/30Uxn1EtjUlXSsivi/0UjlypWLESNGxKWXXhq//fZbgfUqV64cF1xwQVx55ZVRqVKlddtxYJOwcOHCeOGFF+K+++5LLbvkkktiiy22SFvPeRWwvmV6vIpwbgWbXOi9/fbbx/bbb/+H9jF58uRYtWpVRETMnj077r///iLXnTdvXtxxxx0xevTouOeee1KTOAH8UWsm5V3joIMOilq1aqXaS5cuTYVMEVHoiVB++bdfsmSJu1WAP6SkY1VExG+//ZYqNbdq1aro1q1bkftbunRp9OnTJ7744ovo06dPVKtWbd10HEi0H3/8MR588MGYMWNGfPXVV6myS1lZWXHuuefGVVddlba+8ypgfSnt8SrCuRVEbIITWZaFvHWRIiKqVKkSl19+ebz++usxduzY+PTTT+PBBx+MfffdN7XO0KFD46677vqzuwok2C233BIzZsxItfPP7r1o0aK0duXKlUvcZ/5/iOXfB0BplXSsiih4blWhQoU455xz4uWXX47Ro0fHZ599Fk888US0aNEitc7IkSOjU6dOqUnlAEpj0qRJ8fLLL8fIkSPT5hlo06ZNXH311QXWd14FrC+lPV5FOLeCCKH3WslbF2nrrbeO559/Pq655ppo2LBhVK5cOWrVqhVHH310PPvss3Haaael1u3Xr1+MGTNmPfQYSJoHHnggXnnllVS7TZs2cdBBB6Wts3z58rR2dnZ2ifutUCH9BqAVK1asfSeBTV4mx6qI9HOrKlWqxFNPPRU33XRT7LHHHlGlSpWoXr16HHLIIdG3b9+0f9wNGzYshgwZsk7fA5BMRZUbeemll+Loo4+OV199NW258ypgfSnt8SrCuRVERGTluoQTEavrsx199NERsbo+27Bhw4pcd+rUqTFp0qT48ccfo2nTprHnnnsWuW5OTk60adMmvvnmm4iIaNWqVfTq1atsOw9sUh577LG4++67U+0GDRrECy+8EFWqVElbb+bMmXH44Yen2uPHjy+xxNLy5ctjr732SrXff//9QmcCByhJpseqiIhffvklJkyYENOmTYtdd901DjnkkGL3fdFFF8VHH30UERGNGzeOl156qWw7DyTe999/HxUrVow6derE/Pnz4+OPP44HHnggpk6dmlqnR48eceKJJ0aE8ypg/Snt8SrCuRVECL1TShN6l9agQYPipptuioiIqlWrxsiRIwtc9QfIRO/evdMunG299dYxYMCA2G677Qqsu2DBgjjggANS7bFjx5Z4K+7ixYvTSjMNHz48ateuXQY9BzYlpTlWrY2PP/44LrzwwrT2lltuWSb7BjZdCxYsiAsvvDDGjRsXERE1atSIt99+O6pXr+68CtigFHe8WhvOrUgi5U3+BAcffHDq8aJFi9Jm/QbIxMqVK+OWW25JC5G22mqreOqpp4oMkfKPpsw7+VJRlixZktauWrXqWvQW2FStzbFqbRxwwAFpAwjy3sILsLY233zz6NmzZ+r4Mm/evBg6dGhEOK8CNizFHa/WhnMrkkjo/SfIfwvb3Llz109HgI3SkiVL4qqrrooBAwaklm2zzTbRv3//qF+/fpHblS9fPm3m7Tlz5pT4WnnXqVq1akb1KgEi1v5YtTays7OjZs2aqbZzK6CsbL/99mllAEaNGhURzquADU9Rx6u14dyKJBJ6/wlWrVqV1i6p9hvAGnPnzo2//e1vaSWXdt555xgwYEDstNNOJW6fN2j65ZdfSlw/7zr16tUrXWeBTdYfPVatjbznV86tgLLUsGHD1OPff/899dh5FbChKep4tTacW5E0CkuX0rx58+K9996LWbNmxezZs+Oaa66J8uXLF7vNb7/9ltZWFwnIxOzZs+Nvf/tbTJ48ObVsr732iocffjjjepANGzZM1Xn77rvvonnz5sWu/+2336Ye77rrrmvRa2BT80ePVcuXL4+33norfv/995g9e3acf/75JW63fPnymD9/fqrt3Aooyg8//BCff/55TJ06NRo0aBBt2rQpcZusrKzU47yjs51XAetSWR2vnFvBakLvUlq8eHFcd911qfaJJ54YjRo1Knabzz//PPV4m222iTp16qyz/gHJsHDhwrjgggvSQqRDDz00evXqVaCmZHH22Wef1Mzbo0aNivPOO6/Y9fPeErf//vuXstfApqYsjlXlypWL66+/PnJyciIiYu+9946WLVsWu83o0aNjxYoVEbF6JNIee+yxlu8ASLqPP/44brvttoiIaNy4cUYh0vfff596vO2226YeO68C1qWyOl45t4LVlDcppW233TYttH799ddL3Oa5555LPT7mmGPWSb+AZLn22mtj4sSJqfZxxx0XDz30UKkC74jVx5xy5VYf6t9///1YsGBBkevOnz8/Pvzww4hYPWKgRYsWpe84sEkpi2NVhQoVYq+99kq1hwwZUuI2eeuGH3rooVG5cuWMXw/YtDRp0iT1eMKECfHNN98Uu/6vv/4an3zySaqdt16u8ypgXSqr45VzK1hN6L0WTj755NTj/v37x7Rp04pc98knn4yxY8dGxOqrZeecc8467x+wcXvmmWfivffeS7WPPfbY6Nmz51rVVdtiiy1St94uXrw47rnnniLXveuuu2Lx4sUREXHYYYdF3bp1S/16wKajLI9Vec+thg4dGmPGjCly3bfeeiuGDh2aal944YWlfj1g07Hnnnum1by9++67Izc3t9B1V61aFTfffHMsW7YsIiK22267OOyww1LPO68C1qWyPF45twKh91q5+OKLU7PaLl68OC644IL48ssv09ZZvnx59O7dO7p165Zadskll6yzyZyAZJg/f3706NEj1d51113j7rvvLnHugOJ07Ngxtf3AgQPjrrvuSt3qFhGRk5MT3bp1ixdeeCEiIsqXLx8dOnRY69cDkq+sj1V/+ctfUudIq1atissvvzw++uijtHVyc3NjwIAB8c9//jO17JRTTomDDjporV4T2HR06tQp9fiDDz6I66+/PhYuXJi2zq+//hrt27dPTciblZUV//rXv6JSpUpp6zmvAtalsjpeObeCiKzcoi4bbWKmT58eRx99dESsnll7zcGjKJ988klceumlqROcrKysaNKkSey8886xcOHC+Oyzz2LOnDmp9Y8//vjo0aNH6nY4gML07ds3evbsmWofdNBBsfPOO2e8/ZFHHhlHHnlkgeW9e/eOXr16pdpbbbVVHHjggRER8dlnn6VNuHvNNdfE5ZdfvjbdBzYR6+JYNWnSpDj77LPTygXsvvvu0ahRo1i2bFmMGjUqfvnll9RzBx54YDz66KNuvwUy0rNnz+jbt2+qXa1atTjooIOiVq1a8fPPP8fnn38ey5cvTz1/7bXXxqWXXlrovpxXAetSWR2vnFuxqRN6/3+lDb0jVp/QXHvttTFz5swi1ylfvnycf/75cc0116zV7b7ApqVt27YxYcKEtd7+qquuiquvvrrQ53r37h19+vRJTVCSX/ny5aN9+/bRvn37tX59YNOwro5VkydPjg4dOsR3331X4uvfcMMNUa1atbXuA7DpefLJJ6N79+5pI7Pzq1mzZtx4441x0kknFbsv51XAulRWxyvnVmzKhN7/39qE3hERS5cujZdeeimGDRsWEydOjLlz50bVqlWjTp06ceihh0abNm1il112WZddBxKkSZMmsWTJkrXevrjQO2L1Sc9zzz0Xn3zyScycOTNWrlwZ2267bRx00EFx9tlnR6NGjdb6tYFNx7o8Vq1YsSKGDBkSb775ZowfPz5mz54d2dnZsfXWW8fBBx8cp556auyzzz5r/drApm3mzJnx7LPPxkcffRQ//vhjLFmyJGrUqBENGjSIFi1axOmnnx6bb755RvtyXgWsS2V1vHJuxaZK6A0AAAAAQGIoMA0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiSH0BgAAAAAgMYTeAAAAAAAkhtAbAAAAAIDEEHoDAAAAAJAYQm8AAAAAABJD6A0AAAAAQGIIvQEAAAAASAyhNwAAAAAAiVFhfXcAAIA/19y5c2PkyJExbdq0WLZsWVSpUiW23HLL2GWXXWK33XZb390DAAD4Q4TeAJDHUUcdFTNmzEi1//73v0f79u3Xal9Tp06NVq1apdpt2rSJbt26/eE+bqx69eoVvXv3TrXfeeed2G677dZjjzY9ubm50bt373j44Ydj+fLlBZ4/7rjj4r777ivVPkeMGBHnnXdeqn3nnXdG27Zt/3BfSZ7rr78+Xn755VR70qRJ67E3Eb/88ktERGyzzTbrtR/rS94LXEn7/5PjEgCgvAkAFKNPnz7rPZiBstKtW7fo3bt3oYF3RMTuu+/+J/cI/nw5OTnx6KOPRuvWrWPq1KnruzsAAKwDRnoDQDFycnKiS5cuMWjQoKhQwf822Xh999130a9fv7Rle+21V+yzzz6RnZ0dv/32WzRt2nQ99Q7+HN9++2384x//iG+//XZ9dwUAgHXIv94BoAQTJkyIvn37rnWZE9gQvPfee7Fy5cpU+8ILL4zOnTuvxx7Bn2/cuHECbwCATYDQGwAy0KdPn2jZsqVJ/tho/fTTT2nts846q0z2e/DBBysBBAAAbFDU9AaADKwpc7JixYr13RVYK4sXL05rb7vttuupJwAAAOuW0BsAilC1atWoVq1aqr2mzAlsjHJzc9PaFStWXE89AQAAWLeE3gBQhGrVqsX111+ftqxPnz5KOQAAAMAGTE1vACjG6aefHm+88UZ89NFHEfF/ZU4GDRoUFSqUzf9GX3rppejSpUuq/fTTT8fBBx9c4na9evWK3r17p9rvvPNObLfddmnrTJ8+PY4++ugC6+Tk5MTbb78dr776anz77bfx66+/RrVq1WKbbbaJFi1aRLt27WKbbbZJ29eSJUtiyJAhMXjw4Pjhhx9i1qxZUa1atWjYsGG0bNky2rVrF1WqVCn1+582bVo8//zz8d5778VPP/0UK1eujK233jr23HPPOPbYY+Poo4+O8uXLl3q/o0ePjrfeeitGjBgRM2fOjHnz5sXmm28eW2+9dRx00EFx7LHHxgEHHFDifvJ/hm+99VbsuOOOMWrUqOjVq1eMHTs2KlWqFPXq1YvDDz882rZtG9tvv32p+5vfwoULY/DgwTF8+PCYMGFCzJ49O1auXBm1a9eO7bffPpo3bx7HH3987LDDDkXu46ijjooZM2YU+lz++vSZfu/yGzFiRJx33nmp9p133hlt27Yt9vXWvNaqVaviww8/jFdeeSW++uqrmDlzZmRnZ8c222wTTZs2jTPPPDN23nnntP3k/e5Onjw5fv3116hSpUrstNNOcfjhh8fZZ58dtWrVyrj/M2fOjGHDhsVnn30WkyZNirlz58a8efMiIqJ69epRr1692GeffeKkk06KffbZp1Sfzdy5c+OVV16J9957LyZPnhzz58+PatWqxXbbbRdHHXVU/OUvf4k6depERMS+++6bKkFT1GeY36RJk+KNN96I4cOHx4wZM2LOnDlRtWrV2HLLLWP//fePo48+Oo444ohS9Xlt/Pjjj/Hiiy/GJ598Ej/88EMsXbo0ttpqq9htt93i1FNPjVatWkW5cms31mbu3Lmpv8/48eNjzpw5MW/evMjNzY2qVatG3bp1Y6+99opjjz02mjdvXug+8v+G88r73a1Xr14MGzasyL6sXLky3nnnnXjvvfdizJgxMWvWrFi0aFHUrl076tWrF4ceemiceOKJseOOO5bqPY4bNy6GDBkSo0ePjilTpsSiRYtis802i5o1a0aDBg2iadOmccwxx0S9evVKtd+1kZubG0OHDo3BgwfH119/HbNmzYoaNWpEvXr14ogjjoiTTjqp2ONbx44dY/Dgwan2ww8/nPF3MDc3N4466qjU/AP7779/PPvss3/sDeWzcuXKeOONN+Ktt96K8ePHx++//x6VKlWKOnXqxJ577hmnnHJKNG3aNLKyskq132nTpsXQoUPjww8/jGnTpsXs2bOjUqVKscUWW8Q+++wTRx55ZBxzzDHFnjc8//zzceONN6baFSpUiBdffDEaNWpU7Gs/++yz8e9//zvV3nbbbePVV1+NGjVqlOo9AEDSCL0BoARdu3aNE088MRYuXBgR/1fmpH379uu5Z2tn8uTJ0bFjxwIj1pctWxazZs2KCRMmxBNPPBE9e/aMI488MiJWhzLXXntt/Pjjj2nbzJkzJz777LP47LPPol+/ftG3b99o2LBhxn3p379/dO/ePZYsWZK2fMqUKTFlypR47bXXYtddd42bb745o4A6IuKHH36I22+/PT788MMCz82ePTtmz54dEydOjKeffjoOPfTQuPnmm4sNjgvz/vvvx5VXXpmq8b5o0aKYM2dOjB8/PurXr/+HQu9Vq1bF448/Hg899FAsWLCgwPM///xz/PzzzzFy5Mjo1atXtG3bNjp16hTVq1df69dcH3766afo3LlzjBw5Mm35kiVLYu7cuTFx4sTo379/3HzzzdGuXbuIWP23vfbaa2PChAlp28ybNy/Gjh0bY8eOjf79+0fv3r1L/L7Mnj07/vOf/8TLL78cOTk5ha4za9asmDVrVowbNy769esXzZs3j7vuuiu22mqrEt/f888/H3fffXfMnz8/bfmcOXNizpw58eWXX8ajjz4anTt3jjPOOKPE/eX122+/Rbdu3eL1118vULZm7ty5MXfu3Pj2229j4MCBsffee8fNN98ce+65Z6leIxPLly+PHj16RP/+/QvMd/DTTz/FTz/9FO+++27st99+0b1791Lte+nSpXH//ffHgAEDCtSjX2PNe/3qq69i4MCBseeee0b37t0LXCgpCx9++GHccccd8f333xd4bubMmTFz5swYNWpUPPjgg9GuXbvo1KlTiRcB58yZE126dIl33323wHM5OTkxf/78+PHHH+Pdd9+Nu+++O04//fTo0qVLVK5cuczeV14//fRTXHvttTFq1Ki05b/99lv89ttvMWbMmHjwwQfjnHPOiWuuuSays7ML7KNt27ZpoffgwYMzDr1HjhyZNuHuX/7yl7V8J4UbN25c3HDDDTF58uS05UuXLo358+fHN998Ey+//HI0adIk7r333ozmPVi4cGH06NEjnn/++QLHkWXLlsWCBQtiypQp8eqrr0b9+vXjpptuikMOOaTQfZ1++unxzjvvpL4PK1asiBtvvDEGDhxY5IXfH374Ie6+++5Uu1y5cnHPPfcIvAEglDcBgBJtu+220blz57RlG2uZk4kTJ8YZZ5xRYt8XL14c7du3j4kTJ8bIkSPjr3/9a4HAO7/p06fHZZddlro4UJKHH344brvttgKBd36TJ0+OCy64IN55550S9/npp5/GGWecUWjgXZiPPvoo2rVrVyDkKc7s2bOjc+fOhU5qWrFixWjRokXG+8pv6dKlcdFFF8U999xTaOCd34oVK2LQoEFx+umnx5QpU9b6df9sP//8c5xxxhkFAu/8VqxYETfddFO8++678d1338UZZ5xRIPDOb86cOXHllVemhWf5TZ8+Pc4666wYNGhQkYF3YT7++OM466yzYtGiRcWud/fdd8eNN95YIPDOb9GiRfE///M/8eCDD2bch4kTJ8bpp58er732WoHAuzDjxo2Lc845J95+++2MXyMTixcvjgsuuCCefPLJEif4HTVqVJx33nnx22+/ZbTvOXPmxN/+9rd47LHHigy8CzN+/Pg488wz45dffsl4m0w88cQTcemllxYaeOe3YsWKePbZZ+Occ86JX3/9tcj1Fi5cGGeddVahgXdhVq5cGc8991xccsklsXLlyoz7nqmZM2fGeeedV+KxMCcnJ5544om47LLLCj12N23aNC0sfueddzL+G77yyiupx1WqVInjjjsus85n4MMPP4xzzz23QOBdmDFjxsQ555wTc+fOLXa9n376Kc4666x49tlnMzqOfP/993HxxRfHM888U+Q6Xbt2TbtT5csvv4ynn3660HVXrFgRnTp1Svs7XHbZZXHggQeW2BcA2BQIvQEgA+3atYtDDz001V5T5qSksGdDc91118XixYujfPnycdppp8WgQYPiiy++iC+++CIeeeSR2HXXXVPrrly5Mv71r3/FVVddFTk5OVG7du24/vrr47///W98+eWX8f7770eXLl3SRjNOnz49nnvuuYz6MnDgwIhYHRRffPHFMXjw4Bg3blwMHz487r333rRbupcvXx7XXHNNsaHT5MmT4/LLL0+VpoiIaNKkSfTs2TM++OCD+PLLL+Pjjz+O3r17R7NmzVLrzJkzJy699NKYNm1aRv2+9957Y86cOYU+17Rp09h8880z2k9+K1asiA4dOsQnn3ySWlahQoU488wzY8CAAfHZZ5/F2LFj4/XXX48OHTqkjeyeMmVKXHTRRQVCmmHDhsWkSZNi0qRJ0aZNm7Tn1ixf89/alDZZW7feemsqEDz22GPjqaeeik8//TTGjBkTzzzzTIFR2nfeeWdccsklMW/evKhSpUpcddVV8frrr6f+pnfccUdsscUWqfXnzZsXjzzySKGvnZubGx07dky7SNC4cePo3r17vP322zFu3LgYP358fPTRR9G3b99o1apV2vbTpk2Lxx9/vMj3NmjQoHjsscfSlp1wwgnxzDPPpH5rzzzzTJx00kmp5++7776MgsFff/01Lrroovj5559Tyxo0aBC33357DBs2LL788ssYPnx4PPbYY3Hsscem1lmyZEl06NAhxo4dW+JrZOqmm26Kzz//PNXOzs6Oyy+/PF577bXU7/iBBx6IfffdNyJWHxvWlIkqya233hpjxoxJtXfaaae47bbb4o033oixY8fGhAkTYvjw4fHkk09G27Zt00qnzJ07N+699960/W233Xap7/mdd96Z9tzTTz+deq6w0iYvvPBCdOvWLVatWhUREVlZWXHCCSfE448/HiNGjIgvv/wy3nnnnbjtttvSyppMmDAhrrjiili+fHmh7/Gee+6JH374IdVu3rx5PPzww/HRRx/F+PHjY8SIEfHSSy/FueeemzaieuTIkfHyyy+X/CGW0ieffJI6BjZu3Djuu+++GD58eIwbNy5effXVuPDCC9Mmvx0+fHjceuutBfZTrly5OOWUU1LtxYsXZ3TBZenSpfHWW2+l2scdd1xUrVr1j7ylNEOGDImlS5dGuXLl4oQTTognn3wyPvnkk/jyyy9jyJAhcfnll6e9v+nTpxd7MWrx4sVx8cUXp4Xo2267bdxwww3x5ptvxpdffhkjR46MZ555Jk4//fTUd3TlypVx6623pr3XvLbccsu47bbb0pbdd999hf7/6YEHHogvv/wy1W7SpElcddVVmX0gALAJEHoDQIZuu+22tH+ErylzsjFZtGhRVK5cOR588MG4/fbbY5999olq1apFtWrV4vDDD4+nnnoq7bboCRMmxLx582KnnXaKl19+OS644ILYYYcdolKlSrHNNtvE+eefH3369El7jaFDh2bcn1q1asVzzz0XnTp1il133TWys7Ojdu3a0bp163jxxRfjxBNPTK27bNmy+J//+Z9C95OTkxP/+Mc/0ka8XX311fHcc8/FCSecEHXq1IlKlSrFlltuGcccc0w8+eST0aVLl1Td1gULFsQ///nPjPr86aefRkREs2bNYuDAgTFmzJh455134oYbbih1mYq8Bg4cmDbqs1atWqlarfvtt19Ur149KleuHA0bNowrrrgihgwZEnvssUdq/enTp8dNN9201q//Z1q0aFGUK1cuunbtGvfff380bdo0atWqFZtttlkccMAB8fjjj6cFiFOnTo0ZM2ZE7dq1Y9CgQXH11VdHw4YNU3/Tv/zlL9G/f/+oVKlSaps33nij0NdeUzt5jcMOOywGDhyYqlWcnZ0dFStWjK222ipatGgRvXr1ihtuuCFtH6+99lqh+549e3ZaqFq+fPm46667omfPnnHAAQekfmsHHHBAdO/ePe699960oK0k1113Xfz++++pdrt27eLVV1+N0047LerVqxeVKlWK2rVrx6GHHhr3339/2v5zcnKiQ4cOsXTp0oxfrygff/xx2mdQq1atGDhwYFxzzTWxyy67pH7HLVu2jAEDBsSFF16Y8b5Hjx4dQ4YMSbV33333ePHFF6Ndu3ax8847R+XKlaNChQpRu3btaNasWdx5551pcxtErK67X1TYXBpTpkxJCyA322yz6Nu3b/Ts2TOaN28eNWvWjEqVKsV2220X7dq1i9deey2OP/741Prjx48vEMBHrA5MX3311VS7VatW8dhjj8URRxwRW221VVSsWDFq1qwZjRs3jhtvvDHuv//+tPIW/fr1+8PvrSjt2rWL559/Po477rioXbt2ZGdnR6NGjaJz587Rr1+/tIt6L730Uup4mFf+evT/+7//W+Lrvv3222l3CWVS0760qlatGn369ImePXtGs2bNYosttohKlSpFgwYN4pprronevXun1fJ+9dVXi7yb4vbbb4/vvvsu1T7yyCPjtddei/POOy922mmnqFSpUtSoUSMOOOCA6Nq1azz99NNpn92//vWvIu8EOOaYY9IuUi5ZsiRuvvnmtHXGjBmTdv5RrVq16N69e5nNNQIASSD0BoAM1a1bN66//vq0ZX369ImJEyeupx6tnUsuuaTIEhy1a9eOk08+ucDy7t27F5jYco2mTZumRnNGrB5BnMnt91lZWXHfffcVWWu4QoUK0a1bt9h9991Tyz777LMYN25cgXVff/31tFHgZ555Zlx11VXFTkZ2/vnnxwUXXJBqjxs3Lj744IMS+x2x+j0/8sgj0aRJk9hss81iu+22i/POOy+OOeaYjLbPb8mSJWkXD8qXLx+9e/cuduLErbbaKh577LG0+tJvvfVWfP3112vVhz/bqaeeGqeffnqhz2VnZ8dZZ51VYPnNN98cu+yyS6Hb1K9fP21U9uzZswstcZI3rK1YsWLcdtttJQbP5557btStWzfVnjJlSixbtqzAek8++WTaiO0rr7wyTj311CL327p16+jUqVOxr73G559/HsOHD0+1jzjiiLj11luL7Xvr1q3TJsn96aefymSU8MMPP5zWvuuuu9J+p3llZWVF586dMy778/rrr6e1b7nllqhWrVqx2xx99NGx//77p9qLFi2K6dOnZ/R6xXn44YfTLhLccccdxdanrlSpUnTv3j3td/vss88WuANj6tSpaRfoTjvttGKPVS1atEjNrxCx+hg7e/bs0ryVjDRt2jRuvfXWIutH77vvvtG1a9e0ZfnvaoiI2HHHHWO//fZLtYcPHx6zZs0q9rXzXgTYYYcdMp7DoTS6dOlS7PewRYsWcfjhh6fac+fOTRuNv8a0adPSfke777573HfffcV+Tw888MC0uvYLFiwosmxJRMSNN96Ydsz5+OOPU+VfFi1aFJ06dUr7/+wtt9xSJhMoA0CSCL0BoBTatWsXzZs3T7U3tjIn2dnZaUFvYfbee++0dpMmTWKvvfYqdpvddtst9XjNBGwlOfbYY0ssqVGxYsW45ppr0pa98MILBdbr379/6nF2dnZ06NChxNePiLj88svTSgc8++yzGW137bXXlmqEbkk+/PDDtHrHJ598ckahT+3atQu810zfw/p2xRVXFPt8/u9hnTp1CpQayS/v9zAiCg0G99hjjzj22GOjcePGceyxx2Y0WV1WVlZauZ2IKPAdz83NTQvCtthii7j00ktL3PeakaElyT+6t1OnTsUGpWucccYZUadOnVT7j34/Zs6cmVaLff/9989oosL88yIUZccdd4wTTjgh9tlnnzjwwAOjSZMmGW2X966HiIJ/n9KaN29e2gjlvfbaK20Ud1HKly+fVmJiyZIlJV5oyGR+iKuvvjoeeOCB+N///d/44osvonbt2iVuU1o33XRTid+p4447Lu3/Bx9++GHMnDmzwHp5R2qvWLGiwMWMvH7//ff4+OOPU+02bdpk9N0ujR122CFOO+20EtfLG3pHRKEXTwYMGJAWOHfo0KHQST3za9GiRdoFkUGDBhV5gbhatWrRrVu3tM/hrrvuinnz5sVdd92VNsfGKaecklYuCQBYTegNAKXUtWvXtDInX3311UZT5mSvvfYqsU5q3trIEZE2grIoNWvWTGtnUp84kwAiIuLQQw9N2/+IESPSnl+wYEHa5Ib7779/2kRgxVlz+/kan3/+eap2b1Fq1apVIJD9o/IGPhGZfzYRESeddFJaXfXCyg1saLbddtvYYYcdil0n//dw3333TavdXJhMvodXX3113H///fHSSy9Fjx49MutwRIHfTf6J6yZOnJhWruD4449PK7dSlKysrPjLX/5S7Dq5ublpf9cdd9yxyBHv+VWoUCEtlP7mm2/+0CjhTz/9NO030rp164y2q1+/fka/m3PPPTd69uwZgwYNSruYVZKS/j6l9cUXX6Tt4+ijj85422bNmqX9JvMfs9aUiFqjV69e0b9//2JLsjRq1ChatmwZu+22W5nWul6jSZMm0bBhw4zWzVt2Kjc3t9AJaVu3bh2bbbZZqj148OAi9/faa6+lwt9y5coVmH+gLDRr1iyjIL1evXpp7cImFM77W9xss83SLoSX5Kijjko9njdvXrF35hx88MHxt7/9LdWePXt2XHnllan5MCJWf5eKKvsFAJs6oTcAlFLdunULjFrcWMqc5K2TXJT8NUEzGQmbf5ui6qCukZWVlVYSpTjly5dPG8U5ZcqUtHIBY8aMSQvhtttuu4z2u0be0cELFixIq9NamExHnpZG3pItFStWLFWonp2dnVYi5scffyxQTmFDs6F8D4uzfPnymDhxYrz44ovRpUuXeP/994vdd94J5SJK9z0p6bfwww8/pP1NS/sdzztKPTc3t9ASQZnKf5wrqjxRYYor11NaK1asiO+++y4GDx4ct9xyS7z44otpz/+Rv31EpNV9jyjdZ16xYsWoX79+qp13Us6I1QF93jJSy5cvj9tuuy2aNm0a7du3jwEDBqSN5P0z5C1HUpL8d/4UNkFqtWrV0so9jRs3Lm3y2LzyljZp1qxZRr/10irpItsaeS9WRESBCxFLlixJ+w3UqVOnVHf95L9jpKTJZf/5z3+mXYzIO3lshQoVokePHiWW/wGATZWZLgBgLZxxxhnx5ptvpkborilz8vzzz2/QE0mtzS3x+UOAsrDFFluU6h/q+WuVzpo1KzWq95dffkl7btCgQTFo0KC17ttvv/1W7Cjarbfeeq33XZS8I2/r1q2b0QjhvHbaaae00ZZ5P58N0YbyPYyImDNnTowZMya++eab+PHHH2P69Okxffr0+Omnn4qtTZ8/VJ06dWpauzT1dXfeeedin89fPuLjjz8uUMqlNPKW0imtGTNmpLVLEwaX9D4Ls3Dhwhg7dmxMnjw5pkyZEtOnT48ZM2bE9OnTix3N/UdD7/zHlY4dO0bHjh3Xal9z5syJFStWpP2/oXPnzjFmzJj49ttvU8sWLVoUb7/9drz99tsRsXrU8aGHHhpHHHFENG/ePCpXrrxWr5+JTEPhiILf7byTq+bVtm3btBIxgwcPjquvvjptnW+++Sa++uqrtG3WhbwTNJdG/u/Rb7/9lnZcmDJlyh/6LRY1meUa2dnZcffdd8cZZ5xR4Pt+9dVXl/ldRwCQJBvuv8oBYAPXtWvXOPHEE2PRokURsbrMyUMPPZRWz3VDU9owNSLKvLZqRJR6ZFr+9efNm5d6/Edr9+ZX0ijpdREm533NzTffvNTb598m7+ezIdoQvoejR4+OBx98MD755JOMavJXqFCh2PXyl0EozXe8evXqxT5f1n/PP3InwMKFC9PapXmfpVn322+/jd69e8ewYcMKnTQ0v5L+PqVV1seVefPmpZXsqV69ejz77LNx9913x0svvVRoWaUZM2bEwIEDY+DAgVGlSpU49thjo3379utkwsLSHHfyr1vUZ9W0adOoW7duakLZwkLvNZMzRqz+TNZ2MuCSFDU5Z2mV9W8xk/01btw4Tj755LS7GSpVqhRnnHFGmfYFAJJGeRMAWEuFlTl56KGHNugyJ+siwP4z5B9tl3fEY1lPIlpSwFaWE1iu8UdHpeYPzMoq4FlX1uf3MDc3N3r27BlnnnlmfPDBB0V+f7bddts4+uijo1OnTvHqq69mXLt6jeJGiRfWp+L82d/xdSWTyf4iIp555pk4+eSTY+jQoUX2dcstt4zDDz88/v73v8fAgQPj4osvLsuulvlnvnTp0gLLatSoEbfffnu888470bFjx9h3332L/O0uXrw4Xn755Tj++OOLrY+9tkpzDMp/vCnq75qVlRWnnHJKqj116tS0ch6rVq1Key/HH398xt+R9WV9/BanTZsWQ4cOTVu2fPny6Nq1a5n2BQCSxkhvAPgDzjjjjHjjjTfik08+iYj0Mifr2h+dqG19ymSiy7zyj6LNe6t6/lGyN998c/z1r39d+86tB9WrV0+VnChs4rSS5B9pua5KgSTBo48+WmDi2V133TWaN28eu+++e9SvXz923nnnAqOSS5rgNP/3MP+I6OKUtG7+fV988cXRqVOnjPdflvJ/LvPnz0+bsLA4mXwmQ4YMiVtvvTVt2fbbbx+HHXZYNG7cOBo0aBD169cvUK7inXfeyagPmcr/mQ8ZMiQaNGhQpq+xRt26deOSSy6JSy65JObNmxcjRoyIESNGxKeffppW/iRiddh5/fXXx4477limpS2WLFmS8br5/47F3f3Stm3b6NOnT6o9ePDgVG33ESNGpJXuKWlC1w1B/u9F69at4957711nr7dq1aro3Llzof/PfO2116Jly5alviAHAJsKI70B4A/q2rVrVK1aNdVeU+YkU/lHvWY6kmxDn6ywOL///nuBCcKK88MPP6QeV6xYMbbccstUO2/JgIj0+tgbi6222ir1+KeffirVZxMR8f3336e169atWyb9SprZs2fH/fffn2pXqFAh7r777hg8eHBcf/31ccopp8Ree+1VaBmOkgLb/JPvlWYiwpLW3ZC+4/lreOevZV6c/HWy88vJyYnbb789bVmnTp3irbfeiptvvjlOO+202HfffQutz1yaiwyZWF+feY0aNaJVq1Zx0003xeuvvx7vvvtuXHvttWnB8ooVKwpcuPmj1pQgyUT+480222xT5Lo77LBDHHDAAan2mnrlEasvJKzRsGHDjaI+9Z/9vXjsscfiiy++SLUPOeSQtDudbrnllhLrggPApkroDQB/UL169eK6665LW/bQQw/FpEmTMto+/+3smY6CLk3YtKFZtWpVxp/PsmXL0iY622OPPdJugc8flIwbN65UfZk2bVrMmDGjVOUoylre95CTk5NWAqAkS5Ysia+//jrV3nbbbdMuwvB/hg4dmnZB4bzzzksrv1Cc/L+3/OUgmjRpktb+8ssvM+5XSd/ZXXbZJS3oKu13fObMmfHjjz+Wyd0he+65Z1p7zJgxGW87fvz4Yp//+OOP0yZFPPbYY+Piiy+OcuVK/idLSX+f0tprr73S2qX5TUasnqCxqAkeI1b/zr/77rsYPXp0sfupW7duXHrppfHcc8+llVYqbX9KkvcYUpL8fd53332LXb9Nmzapxz///HNMmDAhVq5cGf/9739Ty9fVBJZlrWbNmmmTfq55L5maPXt2fP/99xmVNZk0aVLaRbpatWpFjx494u9//3tq2dy5c+OGG27I+PUBYFMi9AaAMnDmmWfGIYcckmrn5OQUuEW/KPkDykxGbS1ZsqTMQ48/W97AozhDhw5NuxDQtGnTtOe32Wab2HHHHVPtTz/9NFUqpCSrVq2Kiy66KI466qjYa6+94qijjipxNOq6cPDBB6e1X3jhhYy3fe2119LqBeffF/8n7x0DEQW/S0X59ttvY8qUKWnL8pc7adSoUdqI/TfffDPjuzZKqtFcqVKl2G+//dL6U5qQslOnTnHMMcfE3nvvHYcffvgfOnY0a9YsLXx9+eWXMwqYZ8+eHR999FGx6+T/+2T6XZ4zZ07aaNiIosvRZFpP/qCDDkpb97XXXstou4jVF9JOOeWUaN68eey9995xzjnnpD1/5ZVXRpMmTeL444+PK664osTSORERO++8c+y+++6pdlmPMB4xYkRGkyrm5uamTT6ZnZ2d9t0szHHHHZdWAuedd96J0aNHx5w5cyJi9R0XmV582hDk/V4uXLgw3n333Yy3veeee6J169ax9957R/PmzYv8/+Dy5cvjuuuuS7tId+ONN0bt2rXj/PPPj8aNG6eWf/DBB/Hcc8+txTsBgGQTegNAGclf5iTT4DV/KYq8t38X5aGHHipVDdYNUf/+/Uss67Bw4cK47777Uu0KFSrEWWedVWC9M844I/V42bJlcc8992TUh2eeeSY1QnTlypVRvXr1Ym/VX1datmyZVrJl8ODB8fnnn5e43Zw5c9I+n4iIU089tay7lxj5w9k1oVtxcnJy4vrrry90eV7ly5eP0047LdX+7bff4qmnnipx/0OGDMloVHje73hExB133JHRCNNhw4bFiBEjImJ1EJyTkxN77LFHidsVpVatWnHMMcek2t9//308++yzJW7Xq1evEkear83fJ2J1GJh/osiiXiv/nTVFBc7bbrttHHHEEan2119/nfHFqLvvvjv1t1m2bFmBz3u77bZLXRCZM2dOvPXWWyXuc9WqVfHzzz+n2mV9nFqyZElGtamfeuqptFH1p556aqHlgPKqVq1atGrVKtV+++2348MPP0y1DzvssLTj34Yu/2+xZ8+esWjRohK3++qrr+LVV19NtefNmxf7779/oev26tUrbVLsI488Mk488cSIWP0dvuOOO6JChf+bnuuuu+4qVUklANgUCL0BoIwUVuYkE7vttlvUrl071R4+fHi88cYbRa7/0ksvxWOPPbZWfdyQLFq0KNq3b582kVleCxcujCuuuCKt1mzbtm0L1E6OWB1C5K21+uqrr8Zdd91V7AjK999/P+666660Ze3bty/t2ygTlSpViosuuijVXrlyZVx11VXFjsidNWtWXHzxxWkXVw466KBo1qzZOu3rxiz/RIRPPPFEsRePfv/997j88ssLDaXzh6wRq8ul5K29/J///KfYOxo+++yzuOmmmzLoeUSrVq1il112SbVHjhwZ1113XbFlEsaPH18gsL/sssvSRmqvjauuuiotcOvWrVuxE0n269cvBgwYUOJ+8/99Bg0aVOyI5kWLFkWnTp0KvVBY2N8nouAkr8XNjXD55ZenlVb597//nVaHujD3339/WohduXLltN92RMFSHl27di0wyj2/Bx98MO23fuSRRxa7/tp49tln4+mnny7y+TfeeCO6d++eam+22WYF3ltR8pY4mTRpUvzv//5vqr0xTGCZ11577RWHH354qv3dd9/FlVdeWexI+WnTpsVVV12VdqHqzDPPTPt//xqjRo1K+3/85ptvHv/+97/T1mnUqFFcfPHFqfbixYvjuuuuW69lugBgQyP0BoAydOaZZ5Y6dCxXrlza6Nzc3Nzo2LFj3HnnnTF58uRYsmRJ/Prrr/Hee+/FZZddFl26dImcnJyNerLCNaMtJ0+eHG3atIknnngipk2bFsuXL4+ZM2fGoEGD4sQTT4yRI0emtqlfv3506dKl0P1Vq1YtevTokTaK8/HHH49TTjklXnzxxdTkkDNnzozhw4fH3//+97j88svTRoO2bt06bQTrn+3888+PQw89NNWeM2dO/PWvf41bbrklRo0aFQsWLIilS5fGt99+G3379o3jjz8+rUZy7dq144477lgfXd9otGrVKq3MwsSJE+Oss86Kt956K2bPnh0rVqyIX3/9Nb744ou4/fbb44QTTiiyJMeCBQsKLKtdu3badzQnJyeuvvrq6Ny5c3zxxRexcOHCWLx4cXz55Zdx6623xvnnn1/oBIyF1bAuV65c3HvvvWmh7WuvvRbHH3989O/fP6ZOnRrLli2L2bNnx6hRo+KGG26IM888My2I22+//eLss8/O7MMqRoMGDeIf//hHqr18+fJo3759dOnSJcaOHRtLliyJBQsWxPDhw+Pyyy+Prl27Rm5ublpQXphmzZrF1ltvnWrPnDkzTj/99HjllVdi5syZsWLFipg1a1aMGzcu7r333mjdunVaeJpXYX+fiEjbf8TqkcszZsyIFStWFAjY991337QLYcuXL49rrrkmLr/88hg2bFjMnj07li9fHtOmTYshQ4bEaaedFg888EDaPq677rqoU6dO2rJGjRqlRu1GrL4roG3btnHvvffGhAkTYtGiRbFy5cpUSZirr746evXqlVq/WrVqcemllxb6/tbWmmPn7bffHu3bt49PP/005s2bF4sXL47Ro0dH586d4x//+EfaMfOGG25IKy1VnKZNm0a9evVS7TUXM2vVqhUtWrQouzfyJ7njjjvSyhl9+umn0bp163j44Yfjm2++iSVLlsS8efPiyy+/jG7dusXJJ58cM2bMSK2/0047pf2G1li8eHFcf/31aeF1586dC3yHIlZfpN15551T7dGjR8ejjz5aVm8RADZ6xZ95AgCldvvtt8dJJ52U0e3Oa1x++eXxzjvvpG4bz8nJiSeffDKefPLJQtevV69e3HvvvXH66aeXRZf/dPXq1Ysjjjgi+vXrF7NmzYpu3bpFt27dilx/p512ikceeaTAKM28mjVrFvfcc0906dIlNfp18uTJ8a9//avE/hxyyCHrPTAuV65c/Oc//4m///3vMXz48IiIWLFiRQwYMKDEUbJ16tSJhx9+OLbffvs/o6sbrS233DKuvfba6Nq1a2rZ119/HVdffXWx25UrVy5atGgRw4YNSy2bPn16oeueeuqpMWXKlOjTp09E/F8N5Lx1kPPKysqKli1bpo0Ir1SpUqHrNmzYMB588MHo0KFDaoTy9OnT47bbbiu2/xERu+++e/Tq1esPj/Je49JLL41ff/01+vXrFxGr3+dLL70UL730UqHr16pVK84+++zo3bt3kfusVKlS3HzzzXH11Ven7tKYPn16dO7cucT+tGzZMm3E97Rp0wpdb5dddokqVaqk5gkYPXp0HHXUURERUbFixRg1alTa59++fftYsGBB2rH43XffzaiO82WXXVbkRYb/+Z//icmTJ8fkyZMjYnXY2adPn9T3piiVK1eOvn37FhqC/hFXXHFF9O/fP+bOnRtvv/12iWW2OnToUKr//2RlZcWpp55a4KLAySefXGbfyT/TVlttFY8++mja3UizZs2KHj16RI8ePYrdtl69evHQQw/F5ptvXuC5bt26pZWPadasWZGfc6VKlaJr165xzjnnpEoD9erVK4444oho1KjR2r41AEgMI70BoIzVq1cvOnXqVKptatSoEf369cto4rbDDz88BgwYUGDE4sbmX//6V1xyySWFjmrN6/jjj4/nnnsutttuuxL3ecIJJ8Szzz5b4sRqa1SqVCnat28fDz/8cLGB+p+levXq8eijj8bVV19dYILTwpQvXz7atm0br7zyipAjQ+eee2506dIl46Btl112iaeffrpAeYFPP/20yG06dOgQ//73vwsNtfKqVatW/Oc//ylQh72o0DtidQj2/PPPZzw6tly5cvHXv/41+vfvX+Z1k2+88cbo2rVr1KhRo9j1dtppp3jiiSfSRvoWpWXLltGjR48S60SvUbdu3ejdu3fcf//9aaP419Qxz2+zzTaLLl26FDqhZU5OTnz//fdpy7KysqJLly7Rs2fPjPofsToQ7dmzZ/zzn/8scp01x/wTTjgho31GROy///7x3HPPxQEHHJDxNpnaYYcd4sknn0wbOVyYrbfeOu6999644oorSv0abdq0KfC55y/1sjFp1KhRvPDCC3HSSSeV+P+xNY4//vgYNGhQoZ/zBx98EAMHDky1q1SpUuIFrQMOOCD++te/pto5OTnRqVOntAkwAWBTZaQ3AKwDZ555Zrz55pupEbuZqFOnTjz99NPx0UcfxZAhQ+KLL76IX3/9NfVckyZN4uSTT45DDjkkIiJ++eWXddL3P0u5cuWiY8eO0bp16xg4cGCMGDEiZs6cGeXLl49tttkmmjZtGqecckrsvffepdrvnnvuGQMGDIiRI0fGu+++GyNHjoyZM2fG3Llzo0KFClGzZs3YbbfdomnTpnHyySen1QLfEFSoUCGuuuqqOPvss2PIkCHx0UcfxeTJk2P27NmRk5MTNWrUiAYNGkSzZs3ipJNOyuhiAOnOP//8OOaYY2LQoEExYsSImDJlSixYsCAqVKgQm2++eWy//fax++67xxFHHBGHH354Kqjbd999Y/To0RER8d///jdmzZpV5PfnzDPPjGOOOSYGDx4c77zzTvz4448xe/bsqFKlSuywww7RsmXLaNeuXdSqVSsGDx6ctm2tWrWK7f8OO+wQffv2jQkTJsRbb70VI0aMiJ9++ik1+rtGjRrRsGHDOPDAA+OUU07JOKxdG6effnoce+yx8dJLL8WwYcNi0qRJsXDhwqhVq1bstNNO0bp162jTpk1UqVIlvv7664z2efzxx0fTpk3jhRdeiA8//DC+++67mD9/fpQrVy4233zzqFu3bjRq1CgOOeSQaNmyZeoCxtFHHx2vvfZaRKwewT1x4sRCLwa1a9cu6tWrF/369Yvx48fH3Llzo2LFirH11lsXWeP7hBNOiFatWsV///vf+Oijj2Ls2LHx+++/x8KFC6Ny5cqx5ZZbxp577hlHHHFEtGrVKipXrlzi+6xZs2b07NkzrrjiinjttddizJgx8f3338eCBQtixYoVUatWrdhqq63ioIMOiqOOOioOOuigjD6/tbX77rvHyy+/HK+88kq8/vrr8cMPP8S8efOidu3a0bBhw2jZsmWccsopGV2QK8z2228f++67b4waNSoiIho3brzRX6zbYostonv37tG+fft44403Yvjw4fHjjz/GnDlzYtWqVVG9evXYeeedY7/99ouTTz45GjZsWOh+5s6dGzfccEPasg4dOmR0984///nPePfdd1MjzidPnhz/+c9/MrpDAgCSLCs3/zTpAADAn+app55KK6/z9ttvK1VD4qxatSqOPPLI1AXbm266Kc4555z13CsAIKmM9AYAgDIwZMiQ2HLLLWP77bePOnXqZFzyIO+EpFWrVjV6n0QaMWJEKvDOzs5Om8wTAKCsCb0BAKAM3HfffTFlypSIWF1m58UXXyxxm19++SWGDh2aah9wwAGF1puGjd0LL7yQety6deuoWbPm+usMAJB4JrIEAIAysOeee6Yejx8/Pt5+++1i1587d25ceeWVkZOTk1p22mmnrbP+wfoyadKkePPNN1Pt8847bz32BgDYFAi9AQCgDJx55plp7Q4dOkTnzp1j+PDh8fPPP0dOTk4sWbIkvvnmm3jqqaeiTZs2MWHChNT6hx56aLRq1erP7jaUqVmzZsUPP/wQy5cvj3nz5sWQIUPioosuSl3cOeqoo6Jx48bruZcAQNKZyBIAAMpI9+7d45FHHin1dnvvvXc89thjUb169XXQK/jzjB07Ntq1a1foczVq1IjBgwdHnTp1/uReAQCbGiO9AQCgjHTs2DFuu+22qFWrVkbrV6xYMS688MLo16+fwJtE2GGHHQpdXr169XjggQcE3gDAn8JIbwAAKGOLFi2K//73v/HBBx/E119/Hb/++mssWbIkKlasGFtssUU0aNAgmjVrFieddFJstdVW67u7UKauvPLKGDNmTCxYsCC23nrraN68eVxyySWx/fbbr++uAQCbCKE3AAAAAACJobwJAAAAAACJIfQGAAAAACAxhN4AAAAAACSG0BsAAAAAgMQQegMAAAAAkBhCbwAAAAAAEkPoDQAAAABAYgi9AQAAAABIDKE3AAAAAACJ8f8A9HptFfn0V7IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1870x627 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(18.7,6.27)})\n",
    "\n",
    "temporal_samples_count = df_positive.groupby(['hex'])['hex'].count()\n",
    "\n",
    "hist = pd.DataFrame(temporal_samples_count) \\\n",
    "        .rename(columns={'hex': 'count'}) \\\n",
    "        .reset_index(level=0) \\\n",
    "        .groupby(['count'])['count'].count()\n",
    "\n",
    "hist_df = pd.DataFrame(hist) \\\n",
    "          .rename(columns={'count': 'frequency'}) \\\n",
    "          .reset_index(level=0)\n",
    "\n",
    "ax = sns.boxplot(x=hist_df[\"count\"])\n",
    "\n",
    "ax.set_xlabel(\"Number of image dates by hex\",fontsize=30)\n",
    "ax.tick_params(labelsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548ea3c",
   "metadata": {},
   "source": [
    "## Sentinel 2 bands\n",
    "These are the 12 bands contained in the parque files and their respective meanings\n",
    "\n",
    "<div>\n",
    "<img src=\"../res/sentinel2-bands.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf640c8",
   "metadata": {},
   "source": [
    "## 1.2. Build the bidimensional timeseries samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d502d5a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hex</th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B08</th>\n",
       "      <th>B8A</th>\n",
       "      <th>B09</th>\n",
       "      <th>B11</th>\n",
       "      <th>B12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20181029T170421</td>\n",
       "      <td>hex_p_0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>3258.0</td>\n",
       "      <td>3701.0</td>\n",
       "      <td>3692.0</td>\n",
       "      <td>3906.0</td>\n",
       "      <td>3746.0</td>\n",
       "      <td>2627.0</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69338</th>\n",
       "      <td>20190611T165859</td>\n",
       "      <td>hex_p_0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>1459.0</td>\n",
       "      <td>2567.0</td>\n",
       "      <td>3134.0</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>3489.0</td>\n",
       "      <td>3365.0</td>\n",
       "      <td>2825.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68544</th>\n",
       "      <td>20190601T165859</td>\n",
       "      <td>hex_p_0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>1473.0</td>\n",
       "      <td>4137.0</td>\n",
       "      <td>5823.0</td>\n",
       "      <td>5656.0</td>\n",
       "      <td>6130.0</td>\n",
       "      <td>5584.0</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>20181108T170511</td>\n",
       "      <td>hex_p_0</td>\n",
       "      <td>789.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>883.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>1288.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>3071.0</td>\n",
       "      <td>2579.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>20190522T165859</td>\n",
       "      <td>hex_p_0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>3087.0</td>\n",
       "      <td>4515.0</td>\n",
       "      <td>4376.0</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>4181.0</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55447</th>\n",
       "      <td>20190810T165849</td>\n",
       "      <td>hex_n_999</td>\n",
       "      <td>459.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37710</th>\n",
       "      <td>20190122T170619</td>\n",
       "      <td>hex_n_999</td>\n",
       "      <td>525.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2432.0</td>\n",
       "      <td>2326.0</td>\n",
       "      <td>2547.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>1354.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>20190308T170131</td>\n",
       "      <td>hex_n_999</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1781.0</td>\n",
       "      <td>2917.0</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>3317.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12623</th>\n",
       "      <td>20190427T165901</td>\n",
       "      <td>hex_n_999</td>\n",
       "      <td>461.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>951.0</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>2292.0</td>\n",
       "      <td>2588.0</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>2952.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47884</th>\n",
       "      <td>20190701T165859</td>\n",
       "      <td>hex_n_999</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>4853.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106735 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp        hex     B01     B02     B03     B04     B05  \\\n",
       "0      20181029T170421    hex_p_0   527.0   556.0  1080.0   680.0  1532.0   \n",
       "69338  20190611T165859    hex_p_0   977.0   836.0  1042.0   924.0  1459.0   \n",
       "68544  20190601T165859    hex_p_0  1106.0   975.0  1232.0   908.0  1473.0   \n",
       "3216   20181108T170511    hex_p_0   789.0   703.0   883.0   980.0  1288.0   \n",
       "64715  20190522T165859    hex_p_0   865.0   754.0   863.0   626.0  1023.0   \n",
       "...                ...        ...     ...     ...     ...     ...     ...   \n",
       "55447  20190810T165849  hex_n_999   459.0   373.0   337.0   333.0   447.0   \n",
       "37710  20190122T170619  hex_n_999   525.0   706.0   927.0   880.0  1239.0   \n",
       "5537   20190308T170131  hex_n_999  1480.0  1220.0  1420.0  1260.0  1781.0   \n",
       "12623  20190427T165901  hex_n_999   461.0   781.0   984.0   951.0  1388.0   \n",
       "47884  20190701T165859  hex_n_999  1049.0  1104.0  1092.0  1012.0  1330.0   \n",
       "\n",
       "          B06     B07     B08     B8A     B09     B11     B12  label  \n",
       "0      3258.0  3701.0  3692.0  3906.0  3746.0  2627.0  1538.0      1  \n",
       "69338  2567.0  3134.0  3116.0  3489.0  3365.0  2825.0  1692.0      1  \n",
       "68544  4137.0  5823.0  5656.0  6130.0  5584.0  2809.0  1446.0      1  \n",
       "3216   1458.0  1650.0  1648.0  1865.0  2067.0  3071.0  2579.0      1  \n",
       "64715  3087.0  4515.0  4376.0  4705.0  4181.0  2211.0  1020.0      1  \n",
       "...       ...     ...     ...     ...     ...     ...     ...    ...  \n",
       "55447   540.0   640.0   634.0   712.0   862.0   708.0   457.0      0  \n",
       "37710  2020.0  2432.0  2326.0  2547.0  2050.0  2002.0  1354.0      0  \n",
       "5537   2917.0  3153.0  3130.0  3317.0  1915.0  2160.0  1412.0      0  \n",
       "12623  2292.0  2588.0  2734.0  2494.0  2952.0  1983.0  1177.0      0  \n",
       "47884  1799.0  2089.0  1918.0  2136.0  4853.0  1342.0  1031.0      0  \n",
       "\n",
       "[106735 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total rows:106735\n",
      "Number of rows in dataset (positive/negative): (75990/30745)\n",
      "Number of unique hexes(positive/negative): (5066/2050)\n",
      "Total number of samples: 7115 samples of 15x12\n"
     ]
    }
   ],
   "source": [
    "shuffle_imgdates = True\n",
    "\n",
    "number_of_bands = len(band_features)\n",
    "\n",
    "# Keep only [temporal samples] samples \n",
    "df_positive = df_positive.sort_values(by=['hex'])\n",
    "df_positive = df_positive.groupby('hex').head(temporal_samples)\n",
    "\n",
    "df_negative = df_negative.sort_values(by=['hex'])\n",
    "df_negative = df_negative.groupby('hex').head(temporal_samples)\n",
    "\n",
    "# Associate labels picked manually\n",
    "df_negative = df_negative.assign(label=0)\n",
    "df_positive = df_positive.assign(label=1)\n",
    "df = pd.concat([df_positive, df_negative], axis=0)\n",
    "\n",
    "display(df)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format=\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "print('Number of total rows:' +  str(len(df.index)))\n",
    "print('Number of rows in dataset (positive/negative): (%s/%s)' % (str(len(df_positive.index)),str(len(df_negative.index))))\n",
    "print('Number of unique hexes(positive/negative): (%s/%s)' %  (str(df_positive.hex.nunique()), str(df_negative.hex.nunique())))\n",
    "\n",
    "df[band_features] = StandardScaler().fit_transform(df[band_features])\n",
    "\n",
    "# Organize the 2D samples in numpy arrays\n",
    "sample = np.zeros((temporal_samples, number_of_bands), dtype=np.float64)\n",
    "X_array = np.empty((0, temporal_samples, number_of_bands),  dtype=np.float64)\n",
    "\n",
    "labels = []\n",
    "hexes = []\n",
    "timestamp_tracking = []\n",
    "timestamp_sample = []\n",
    "\n",
    "sub_index = 0\n",
    "count = 0;\n",
    "for index, row in df.iterrows():\n",
    "        pct_complete = count/df.shape[0] * 100\n",
    "        print('Sampling {0:.2f}'.format(pct_complete) + '%', end='\\r')\n",
    "        count = count + 1\n",
    "\n",
    "        # fill the band values in a temporal row\n",
    "        for idx,b in enumerate(band_features):\n",
    "            sample[sub_index][idx] = row[b]\n",
    "\n",
    "        timestamp_sample.append(row.timestamp)\n",
    "\n",
    "        # increment row number \n",
    "        sub_index = sub_index + 1\n",
    "\n",
    "        # if reached last row of temporal samples, increment to next sample\n",
    "        if sub_index == temporal_samples:\n",
    "            shuffler = np.random.permutation(sample.shape[0])\n",
    "            sample = sample[shuffler]\n",
    "            timestamp_sample = list(np.array(timestamp_sample)[shuffler])\n",
    "\n",
    "            X_array = np.append(X_array, [sample], axis=0)\n",
    "            labels.append(row.label)\n",
    "            hexes.append(row.hex)\n",
    "            timestamp_tracking.append(timestamp_sample.copy())            \n",
    "\n",
    "            timestamp_sample.clear()\n",
    "            sub_index = 0\n",
    "\n",
    "print('Total number of samples: %d samples of %dx%d' % (X_array.shape[0],X_array.shape[1],X_array.shape[2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e958d49e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\en89912\\AppData\\Local\\Temp\\ipykernel_25640\\668683560.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b5bda",
   "metadata": {},
   "source": [
    "## 1.3. Visualize samples in the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "model = TSNE(n_components=2, perplexity=4, random_state=0)\n",
    "tsne_data = model.fit_transform(X_array.reshape(X_array.shape[0], number_of_bands * temporal_samples))\n",
    "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\"))\n",
    "tsne_data = pd.concat([tsne_df, pd.DataFrame(labels, columns=['y'])], axis=1)\n",
    "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"y\"))\n",
    "\n",
    "sns.jointplot(data=tsne_df, x=\"Dim_1\", y=\"Dim_2\", hue='y')\n",
    "plt.show()\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c4bc1",
   "metadata": {},
   "source": [
    "## 1.4. Visualize the bidimensional timeseries samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff864e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11,8)})\n",
    "\n",
    "for i in range(0,3):\n",
    "    # This is what a positive sample looks like\n",
    "    ax = sns.heatmap(X_array[i], annot=False, cmap=\"viridis\", vmin=-2, vmax=2, \n",
    "                     xticklabels=range(1,13), yticklabels=range(1,16), \n",
    "                     fmt='g', annot_kws={\"fontsize\":24}, cbar=True)\n",
    "    ax.set_xlabel(\"Band\",fontsize=24)\n",
    "    ax.set_ylabel(\"Image date\",fontsize=24)\n",
    "    ax.set_title('Sample: ' + hexes[i], fontsize=26)\n",
    "    ax.tick_params(labelsize=20)\n",
    "    \n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "for i in range(-4,-1):  \n",
    "    ax = sns.heatmap(X_array[i], annot=False, cmap=\"rocket\", vmin=-2, vmax=2, \n",
    "                     xticklabels=range(1,13), yticklabels=range(1,16), \n",
    "                     fmt='g', annot_kws={\"fontsize\":20}, cbar=True)\n",
    "    ax.set_xlabel(\"Band\",fontsize=24)\n",
    "    ax.set_ylabel(\"Image date\",fontsize=24)\n",
    "    ax.set_title('Sample: ' + hexes[i], fontsize=26)\n",
    "    ax.tick_params(labelsize=20)\n",
    "    \n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9be7d",
   "metadata": {},
   "source": [
    "## 1.5. Visualize the range of band values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b156ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "value_vars = [i for i in df.columns if (i.startswith('B') or i.startswith('m'))]\n",
    "id_vars = ['label']\n",
    "data = pd.melt(df, id_vars=id_vars, value_vars=value_vars)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11,8)})\n",
    "sns.boxplot(x=\"variable\", y=\"value\", hue='label', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bde741",
   "metadata": {},
   "source": [
    "## 1.6. Check correlation among bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corr,mask=mask,cmap=cmap, annot=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f401ced5",
   "metadata": {},
   "source": [
    "<a id='model_training'></a>\n",
    "\n",
    "# 2. Contrastive Learning (SimCLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total of samples:', X_array.shape)\n",
    "\n",
    "labels_and_hexes = np.vstack((hexes, labels)).T\n",
    "\n",
    "# 80% for training, 10% test and 10% validation\n",
    "X_train, X_test, yl_train, yl_test = train_test_split(X_array, labels_and_hexes, test_size=0.2, random_state=42)\n",
    "X_val, X_test, yl_val, yl_test = train_test_split(X_test, yl_test, test_size=0.5, random_state=42)\n",
    "\n",
    "labeled_train_samples = X_train.shape[0]\n",
    "hexes_train, y_train = np.hsplit(yl_train, 2)\n",
    "hexes_test, y_test = np.hsplit(yl_test, 2)\n",
    "hexes_val, y_val = np.hsplit(yl_val, 2)\n",
    "\n",
    "y_val = np.array(y_val).T[0]\n",
    "y_test = np.array(y_test).T[0]\n",
    "y_train = np.array(y_train).T[0]\n",
    "hexes_val = np.array(hexes_val).T[0]\n",
    "hexes_test = np.array(hexes_test).T[0]\n",
    "hexes_train = np.array(hexes_train).T[0]\n",
    "\n",
    "y_train = y_train.astype(np.int)\n",
    "y_test = y_test.astype(np.int)\n",
    "y_val = y_val.astype(np.int)\n",
    "\n",
    "print('Total of training samples:',X_train.shape, len(y_train))\n",
    "print('Total of test samples:', X_test.shape, len(y_test))\n",
    "print('Total of validation samples:', X_val.shape, len(y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25adbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    labeled_batch_size = labeled_train_samples // steps_per_epoch\n",
    "    batch_size = labeled_batch_size\n",
    " \n",
    "    train_dataset = tf.data.Dataset\\\n",
    "        .from_tensor_slices((X_train, y_train))\\\n",
    "        .shuffle(buffer_size=10 * labeled_batch_size)\\\n",
    "        .batch(labeled_batch_size)\n",
    "    \n",
    "    test_dataset = tf.data.Dataset\\\n",
    "        .from_tensor_slices((X_test, y_test))\\\n",
    "        .batch(batch_size)\\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    validation_dataset = tf.data.Dataset\\\n",
    "        .from_tensor_slices((X_val, y_val))\\\n",
    "        .batch(5)\\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    full_dataset = tf.data.Dataset\\\n",
    "        .from_tensor_slices((X_array, labels))\\\n",
    "        .batch(5)\\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return batch_size, train_dataset, test_dataset, validation_dataset, full_dataset\n",
    "\n",
    "    \n",
    "    \n",
    "batch_size, train_dataset, test_dataset, validation_dataset, full_dataset = prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18538b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distorts the color distibutions of images\n",
    "class RandomAugmentSatelliteBands(layers.Layer):\n",
    "    def __init__(self, jitter=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.jitter = jitter\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"jitter\": self.jitter})\n",
    "        return config\n",
    "\n",
    "    def call(self, images, training=True):\n",
    "        if training:\n",
    "            batch_size = tf.shape(images)[0]\n",
    "            \n",
    "            \n",
    "            # jitter colors\n",
    "            #jitter_matrices = tf.random.uniform(\n",
    "            #    (batch_size, temporal_samples, 1), minval=1 - self.jitter, maxval=1 + self.jitter\n",
    "            #)\n",
    "            \n",
    "            jitter_matrices = tf.random.uniform(\n",
    "                (batch_size, temporal_samples, 1), minval=1.3, maxval=1.3\n",
    "            )\n",
    "            \n",
    "            jitter_matrices = tf.concat([jitter_matrices,jitter_matrices,jitter_matrices,jitter_matrices,\n",
    "                                         jitter_matrices,jitter_matrices,jitter_matrices,jitter_matrices,\n",
    "                                         jitter_matrices,jitter_matrices,jitter_matrices,jitter_matrices], axis=2)\n",
    "            \n",
    "            \n",
    "            \n",
    "            images = tf.round(images * jitter_matrices)\n",
    "            \n",
    "            # shuffle dates\n",
    "            #images = tf.random.shuffle(tf.transpose(images, [1, 0, 2]))\n",
    "            #images = tf.transpose(images, [1, 0, 2])\n",
    "            \n",
    "            \n",
    "        return images\n",
    "\n",
    "# Define the encoder architecture\n",
    "def get_encoder():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(temporal_samples, number_of_bands)),\n",
    "            layers.Conv1D(width, kernel_size=kernel_size, strides=strides, activation=\"relu\"),\n",
    "            layers.Conv1D(width, kernel_size=kernel_size, strides=strides, activation=\"relu\"),\n",
    "            layers.Conv1D(width, kernel_size=kernel_size, strides=strides, activation=\"relu\"),\n",
    "            layers.Conv1D(width, kernel_size=kernel_size, strides=strides, activation=\"relu\"),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(width, activation=\"relu\"),\n",
    "        ],\n",
    "        name=\"encoder\",\n",
    "    )\n",
    "\n",
    "# Image augmentation module\n",
    "def get_augmenter(jitter):\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(temporal_samples, number_of_bands)),\n",
    "            RandomAugmentSatelliteBands(jitter),\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6a8b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_augmentations(num_images):\n",
    "    # Sample a batch from a dataset\n",
    "    images = next(iter(train_dataset))[0][:num_images]\n",
    "\n",
    "    # Apply augmentations\n",
    "    augmented_images = zip(\n",
    "        images,\n",
    "        get_augmenter(**classification_augmentation)(images),\n",
    "        get_augmenter(**contrastive_augmentation)(images),\n",
    "    )\n",
    "    row_titles = [\n",
    "        \"Original:\",\n",
    "        \"Weakly augmented:\",\n",
    "        \"Strongly augmented:\",\n",
    "    ]\n",
    "    plt.figure(figsize=(num_images * 2.5, 4 * 2.5), dpi=100)\n",
    "    for column, image_row in enumerate(augmented_images):\n",
    "        for row, image in enumerate(image_row):\n",
    "            plt.subplot(4, num_images, row * num_images + column + 1)\n",
    "            plt.imshow(image)\n",
    "            if column == 0:\n",
    "                plt.title(row_titles[row], loc=\"left\")\n",
    "            plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "visualize_augmentations(num_images=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline supervised training with random initialization\n",
    "baseline_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(temporal_samples, number_of_bands)),\n",
    "        get_augmenter(**classification_augmentation),\n",
    "        get_encoder(),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ],\n",
    "    name=\"baseline_model\",\n",
    ")\n",
    "baseline_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    train_dataset, epochs=num_epochs, validation_data=test_dataset\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(baseline_history.history[\"val_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1dc23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the contrastive model with model-subclassing\n",
    "\n",
    "class ContrastiveModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.contrastive_augmenter = get_augmenter(**contrastive_augmentation)\n",
    "        self.classification_augmenter = get_augmenter(**classification_augmentation)\n",
    "        self.encoder = get_encoder()\n",
    "\n",
    "        \n",
    "        # Non-linear MLP as projection head\n",
    "        self.projection_head = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=(width,)),\n",
    "                layers.Dense(width, activation=\"relu\"),\n",
    "                layers.Dense(width),\n",
    "            ],\n",
    "            name=\"projection_head\",\n",
    "        )\n",
    "        # Single dense layer for linear probing\n",
    "        self.linear_probe = keras.Sequential(\n",
    "            [layers.Input(shape=(width,)), layers.Dense(1, activation='sigmoid')], name=\"linear_probe\"\n",
    "        )\n",
    "\n",
    "        self.encoder.summary()\n",
    "        self.projection_head.summary()\n",
    "        self.linear_probe.summary()\n",
    "\n",
    "    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.contrastive_optimizer = contrastive_optimizer\n",
    "        self.probe_optimizer = probe_optimizer\n",
    "\n",
    "        # self.contrastive_loss will be defined as a method\n",
    "        self.probe_loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n",
    "        self.contrastive_accuracy = keras.metrics.BinaryAccuracy(name=\"c_acc\")\n",
    "        self.probe_loss_tracker = keras.metrics.Mean(name=\"p_loss\")\n",
    "        self.probe_accuracy = keras.metrics.BinaryAccuracy(name=\"p_acc\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.contrastive_loss_tracker,\n",
    "            self.contrastive_accuracy,\n",
    "            self.probe_loss_tracker,\n",
    "            self.probe_accuracy,\n",
    "        ]\n",
    "\n",
    "    def contrastive_loss(self, projections_1, projections_2):\n",
    "        # InfoNCE loss (information noise-contrastive estimation)\n",
    "        # NT-Xent loss (normalized temperature-scaled cross entropy)\n",
    "\n",
    "        # Cosine similarity: the dot product of the l2-normalized feature vectors\n",
    "        projections_1 = tf.math.l2_normalize(projections_1, axis=1)\n",
    "        projections_2 = tf.math.l2_normalize(projections_2, axis=1)\n",
    "        \n",
    "        \n",
    "        similarities = (\n",
    "            tf.matmul(projections_1, projections_2, transpose_b=True) / self.temperature\n",
    "        )        \n",
    "\n",
    "        # The similarity between the representations of two augmented views of the\n",
    "        # same hex should be higher than their similarity with other views\n",
    "        batch_size = tf.shape(projections_1)[0]\n",
    "    \n",
    "        contrastive_labels = tf.range(batch_size)\n",
    "        self.contrastive_accuracy.update_state(contrastive_labels, similarities)\n",
    "        self.contrastive_accuracy.update_state(contrastive_labels, tf.transpose(similarities))\n",
    "\n",
    "        # The temperature-scaled similarities are used as logits for cross-entropy\n",
    "        # a symmetrized version of the loss is used here\n",
    "        loss_1_2 = keras.losses.binary_crossentropy(\n",
    "            contrastive_labels, similarities, from_logits=False\n",
    "        )\n",
    "        \n",
    "        loss_2_1 = keras.losses.binary_crossentropy(\n",
    "            contrastive_labels, tf.transpose(similarities), from_logits=False\n",
    "        )\n",
    "        \n",
    "        \n",
    "        return (loss_1_2 + loss_2_1) / 2\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (labeled_images, labels) = data\n",
    "\n",
    "        # Both labeled and unlabeled images are used, without labels\n",
    "        images = labeled_images\n",
    "        \n",
    "        # Each image is augmented twice, differently\n",
    "        augmented_images_1 = self.contrastive_augmenter(images, training=True)\n",
    "        augmented_images_2 = self.contrastive_augmenter(images, training=True)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            features_1 = self.encoder(augmented_images_1, training=True)\n",
    "            features_2 = self.encoder(augmented_images_2, training=True)\n",
    "            # The representations are passed through a projection mlp\n",
    "            projections_1 = self.projection_head(features_1, training=True)\n",
    "            projections_2 = self.projection_head(features_2, training=True)\n",
    "            contrastive_loss = self.contrastive_loss(projections_1, projections_2)\n",
    "        gradients = tape.gradient(\n",
    "            contrastive_loss,\n",
    "            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "        )\n",
    "        self.contrastive_optimizer.apply_gradients(\n",
    "            zip(\n",
    "                gradients,\n",
    "                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "            )\n",
    "        )\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "\n",
    "        # Labels are only used in evalutation for an on-the-fly logistic regression\n",
    "        preprocessed_images = self.classification_augmenter(\n",
    "            labeled_images, training=True\n",
    "        )\n",
    "        with tf.GradientTape() as tape:\n",
    "            # the encoder is used in inference mode here to avoid regularization\n",
    "            # and updating the batch normalization paramers if they are used\n",
    "            features = self.encoder(preprocessed_images, training=False)\n",
    "            class_logits = self.linear_probe(features, training=True)\n",
    "            probe_loss = self.probe_loss(labels, class_logits)\n",
    "        gradients = tape.gradient(probe_loss, self.linear_probe.trainable_weights)\n",
    "        self.probe_optimizer.apply_gradients(\n",
    "            zip(gradients, self.linear_probe.trainable_weights)\n",
    "        )\n",
    "        self.probe_loss_tracker.update_state(probe_loss)\n",
    "        self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        labeled_images, labels = data\n",
    "\n",
    "        # For testing the components are used with a training=False flag\n",
    "        preprocessed_images = self.classification_augmenter(\n",
    "            labeled_images, training=False\n",
    "        )\n",
    "        features = self.encoder(preprocessed_images, training=False)\n",
    "        class_logits = self.linear_probe(features, training=False)\n",
    "        probe_loss = self.probe_loss(labels, class_logits)\n",
    "        self.probe_loss_tracker.update_state(probe_loss)\n",
    "        self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        # Only the probe metrics are logged at test time\n",
    "        return {m.name: m.result() for m in self.metrics[2:]}\n",
    "\n",
    "\n",
    "# Contrastive pretraining\n",
    "pretraining_model = ContrastiveModel()\n",
    "\n",
    "pretraining_model.compile(\n",
    "    contrastive_optimizer=keras.optimizers.Adam(),\n",
    "    probe_optimizer=keras.optimizers.Adam(),\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "pretraining_history = pretraining_model.fit(\n",
    "    train_dataset, epochs=num_epochs, validation_data=train_dataset\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(pretraining_history.history[\"val_p_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087e7db",
   "metadata": {},
   "source": [
    "# Encoding a few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fc0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder for validation\n",
    "encoder_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(temporal_samples, number_of_bands)),\n",
    "        get_augmenter(**classification_augmentation),\n",
    "        pretraining_model.encoder,\n",
    "    ],\n",
    "    name=\"encoder_model\",\n",
    ")\n",
    "\n",
    "encoded_vectors = encoder_model.predict(X_val)\n",
    "\n",
    "print(encoded_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f813ac",
   "metadata": {},
   "source": [
    "# Visualization of the encoded samples in the XY space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79318a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "tsne_data = model.fit_transform(encoded_vectors)\n",
    "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\"))\n",
    "\n",
    "tsne_df = pd.concat([tsne_df, pd.DataFrame(y_val, columns=['y'])], axis=1)\n",
    "\n",
    "sns.jointplot(data=tsne_df, x=\"Dim_1\", y=\"Dim_2\", hue='y')\n",
    "plt.show()\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b92f47",
   "metadata": {},
   "source": [
    "## Finetuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a787386",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Supervised finetuning of the pretrained encoder\n",
    "finetuning_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(temporal_samples, number_of_bands)),\n",
    "        get_augmenter(**classification_augmentation),\n",
    "        pretraining_model.encoder,\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ],\n",
    "    name=\"finetuning_model\",\n",
    ")\n",
    "finetuning_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "finetuning_history = finetuning_model.fit(\n",
    "    train_dataset, epochs=num_epochs, validation_data=test_dataset\n",
    ")\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(finetuning_history.history[\"val_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classification accuracies of the baseline and the pretraining + finetuning process:\n",
    "def plot_training_curves(pretraining_history, finetuning_history, baseline_history):\n",
    "    for metric_key, metric_name in zip([\"acc\", \"loss\"], [\"accuracy\", \"loss\"]):\n",
    "        plt.figure(figsize=(8, 5), dpi=100)\n",
    "        plt.plot(\n",
    "            baseline_history.history[f\"val_{metric_key}\"], label=\"supervised baseline\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            pretraining_history.history[f\"val_p_{metric_key}\"],\n",
    "            label=\"self-supervised pretraining\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            finetuning_history.history[f\"val_{metric_key}\"],\n",
    "            label=\"supervised finetuning\",\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.title(f\"Classification {metric_name} during training\")\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(f\"validation {metric_name}\")\n",
    "\n",
    "\n",
    "plot_training_curves(pretraining_history, finetuning_history, baseline_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190380b",
   "metadata": {},
   "source": [
    "<a id='siamese_triplet_loss'></a>\n",
    "\n",
    "# 3. Siamese Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array_n = X_array[np.array(labels) == 0]\n",
    "X_array_p = X_array[np.array(labels) == 1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('Total of samples:', X_array.shape)\n",
    "\n",
    "labels_and_hexes = np.vstack((hexes, labels)).T\n",
    "\n",
    "X_array_anchors = X_array_p[0:math.floor((X_array_p.shape[0]/2))]\n",
    "X_array_positives = X_array_p[math.floor(X_array_p.shape[0]/2):-1]\n",
    "X_array_negatives = X_array_n[0:math.floor((X_array_p.shape[0]/2))]\n",
    "\n",
    "print('Total of anchors samples:', X_array_anchors.shape)\n",
    "print('Total of positive samples:', X_array_positives.shape)\n",
    "print('Total of negative samples:', X_array_negatives.shape)\n",
    "\n",
    "samples_count = X_array_anchors.shape[0]\n",
    "print('Number of samples:', samples_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    anchor_dataset = tf.data.Dataset\\\n",
    "        .from_tensor_slices(X_array_anchors)\n",
    "\n",
    "    positive_dataset = tf.data.Dataset\\\n",
    "        .from_tensor_slices(X_array_positives)\n",
    "    \n",
    "    negative_dataset = tf.data.Dataset\\\n",
    "        .from_tensor_slices(X_array_negatives)\n",
    "    \n",
    "    return anchor_dataset, positive_dataset, negative_dataset\n",
    "   \n",
    "anchor_dataset, positive_dataset, negative_dataset = prepare_dataset()\n",
    "print(anchor_dataset, positive_dataset, negative_dataset)\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "dataset = dataset.shuffle(buffer_size=128)\n",
    "\n",
    "# Let's now split our dataset in train and validation.\n",
    "siamese_train_dataset = dataset.take(round(samples_count * 0.8))\n",
    "siamese_train_dataset = siamese_train_dataset.batch(32, drop_remainder=False)\n",
    "\n",
    "siamese_validation_dataset = dataset.skip(round(samples_count * 0.8))\n",
    "siamese_validation_dataset = siamese_validation_dataset.batch(32, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0434c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder architecture\n",
    "def get_encoder():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(temporal_samples, number_of_bands)),\n",
    "            layers.Conv1D(width, kernel_size=3, strides=1, activation=\"relu\"),\n",
    "            layers.Conv1D(width, kernel_size=3, strides=1, activation=\"relu\"),\n",
    "            layers.Conv1D(width, kernel_size=3, strides=1, activation=\"relu\"),\n",
    "            layers.Conv1D(width, kernel_size=3, strides=1, activation=\"relu\"),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(width, activation=\"relu\"),\n",
    "        ],\n",
    "        name=\"encoder\",\n",
    "    )\n",
    "\n",
    "embedding = get_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "\n",
    "\n",
    "anchor_input = layers.Input(name=\"anchor\", shape=(15,12))\n",
    "positive_input = layers.Input(name=\"positive\", shape=(15,12))\n",
    "negative_input = layers.Input(name=\"negative\", shape=(15,12))\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    embedding(anchor_input),\n",
    "    embedding(positive_input),\n",
    "    embedding(negative_input),\n",
    ")\n",
    "\n",
    "siamese_network = Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80190e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super().__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # The output of the network is a tuple containing the distances\n",
    "        # between the anchor and the positive example, and the anchor and\n",
    "        # the negative example.\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86716e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = SiameseModel(siamese_network)\n",
    "siamese_model.compile(optimizer=keras.optimizers.Adam(0.0001))\n",
    "siamese_model.fit(siamese_train_dataset, epochs=50, validation_data=siamese_validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(siamese_train_dataset))\n",
    "\n",
    "anchor, positive, negative = sample\n",
    "\n",
    "anchor_embedding, positive_embedding, negative_embedding = (\n",
    "    embedding(anchor),\n",
    "    embedding(positive),\n",
    "    embedding(negative),\n",
    ")\n",
    "\n",
    "cosine_similarity = keras.metrics.CosineSimilarity()\n",
    "\n",
    "positive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
    "print(\"Positive similarity:\", positive_similarity.numpy())\n",
    "\n",
    "negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
    "print(\"Negative similarity\", negative_similarity.numpy())\n",
    "\n",
    "posneg_similarity = cosine_similarity(positive_embedding, negative_embedding)\n",
    "print(\"PosNeg similarity\", posneg_similarity.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a95187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('Total of samples:', X_array.shape)\n",
    "\n",
    "labels_and_hexes = np.vstack((hexes, labels)).T\n",
    "\n",
    "# 80% for training, 10% test and 10% validation\n",
    "X_train, X_test, yl_train, yl_test = train_test_split(X_array, labels_and_hexes, test_size=0.2, random_state=42)\n",
    "X_val, X_test, yl_val, yl_test = train_test_split(X_test, yl_test, test_size=0.5, random_state=42)\n",
    "\n",
    "labeled_train_samples = X_train.shape[0]\n",
    "hexes_train, y_train = np.hsplit(yl_train, 2)\n",
    "hexes_test, y_test = np.hsplit(yl_test, 2)\n",
    "hexes_val, y_val = np.hsplit(yl_val, 2)\n",
    "\n",
    "y_val = np.array(y_val).T[0]\n",
    "y_test = np.array(y_test).T[0]\n",
    "y_train = np.array(y_train).T[0]\n",
    "hexes_val = np.array(hexes_val).T[0]\n",
    "hexes_test = np.array(hexes_test).T[0]\n",
    "hexes_train = np.array(hexes_train).T[0]\n",
    "\n",
    "y_train = y_train.astype(np.int)\n",
    "y_test = y_test.astype(np.int)\n",
    "y_val = y_val.astype(np.int)\n",
    "\n",
    "print('Total of training samples:',X_train.shape, len(y_train))\n",
    "print('Total of test samples:', X_test.shape, len(y_test))\n",
    "print('Total of validation samples:', X_val.shape, len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee824f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Supervised finetuning of the pretrained encoder\n",
    "finetuning_siamese_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(temporal_samples, number_of_bands)),\n",
    "        get_encoder(),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ],\n",
    "    name=\"finetuning_model\",\n",
    ")\n",
    "finetuning_siamese_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "finetuning_siamese_history = finetuning_siamese_model.fit(\n",
    "    train_dataset, epochs=num_epochs * 10 , validation_data=validation_dataset\n",
    ")\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(finetuning_siamese_history.history[\"val_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05cdf0",
   "metadata": {},
   "source": [
    "<a id='pu_learning'></a>\n",
    "\n",
    "# 4. Positive Unlabeled Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aba060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "X_train_reshaped = np.reshape(X_train, (X_train.shape[0], X_train.shape[1] * X_train.shape[2]))\n",
    "X_test_reshaped = np.reshape(X_test, (X_test.shape[0], X_test.shape[1] * X_test.shape[2]))\n",
    "X_val_reshaped = np.reshape(X_val, (X_val.shape[0], X_val.shape[1] * X_val.shape[2]))\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X_train_reshaped, y_train)\n",
    "h_rus = hexes_train[rus.sample_indices_]\n",
    "\n",
    "print(X_rus.shape, np.array(y_rus).shape, np.array(h_rus).shape)\n",
    "\n",
    "print(sum(np.array(y_train)==0),sum(np.array(y_train)==1))\n",
    "print(sum(np.array(y_rus)==0),sum(np.array(y_rus)==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import baggingPU\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "bc = baggingPU.BaggingClassifierPU(SVC(gamma='auto'), \n",
    "                         n_estimators = 50, \n",
    "                         n_jobs = -1, \n",
    "                         max_samples = sum(y_rus)  # Each training sample will be balanced \n",
    "                        )\n",
    "bc.fit(X_rus, y_rus)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9296cca6",
   "metadata": {},
   "source": [
    "<a id='results'></a>\n",
    "\n",
    "# 5. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc203f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score,f1_score,matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "baseline_pred = baseline_model.predict(validation_dataset)\n",
    "baseline_result = np.where(baseline_pred > 0.5, 1, 0)\n",
    "print('Baseline Accuracy: {:.2f}%'.format(accuracy_score(y_val, baseline_result) * 100))\n",
    "print('Baseline Recall: {:.2f}%'.format(recall_score(y_val, baseline_result) * 100))\n",
    "print('Baseline Precision: {:.2f}%'.format(precision_score(y_val, baseline_result) * 100))\n",
    "print('Baseline F1: {:.2f}%'.format(f1_score(y_val, baseline_result) * 100))\n",
    "m = confusion_matrix(y_val, baseline_result)\n",
    "print('Baseline Acc by Class', (m.diagonal()/m.sum(axis=1)))\n",
    "print(confusion_matrix(y_val, baseline_result))\n",
    "\n",
    "simclr_output = finetuning_model.predict(validation_dataset)\n",
    "simclr_result = np.where(simclr_output > 0.5, 1, 0)\n",
    "\n",
    "print('Contrastive Accuracy: {:.2f}%'.format(accuracy_score(y_val, simclr_result) * 100))\n",
    "print('Contrastive Recall: {:.2f}%'.format(recall_score(y_val, simclr_result) * 100))\n",
    "print('Contrastive Precision: {:.2f}%'.format(precision_score(y_val, simclr_result) * 100))\n",
    "print('Contrastive F1: {:.2f}%'.format(f1_score(y_val, simclr_result) * 100))\n",
    "m = confusion_matrix(y_val, simclr_result)\n",
    "print('Contrastive Acc by Class', (m.diagonal()/m.sum(axis=1)))\n",
    "print(confusion_matrix(y_val, simclr_result))\n",
    "\n",
    "siamese_output = finetuning_siamese_model.predict(validation_dataset)\n",
    "siamese_result = np.where(siamese_output > 0.5, 1, 0)\n",
    "\n",
    "print('Triplet Loss Accuracy: {:.2f}%'.format(accuracy_score(y_val, siamese_result) * 100))\n",
    "print('Triplet Loss Recall: {:.2f}%'.format(recall_score(y_val, siamese_result) * 100))\n",
    "print('Triplet Loss Precision: {:.2f}%'.format(precision_score(y_val, siamese_result) * 100))\n",
    "print('Triplet Loss F1: {:.2f}%'.format(f1_score(y_val, siamese_result) * 100))\n",
    "m = confusion_matrix(y_val, siamese_result)\n",
    "print('Triplet Loss Acc by Class', (m.diagonal()/m.sum(axis=1)))\n",
    "print(confusion_matrix(y_val, siamese_result))\n",
    "\n",
    "pu_result = bc.predict(X_val_reshaped)\n",
    "\n",
    "print('Validation Dataset')\n",
    "print('Precision: ', precision_score(y_val, pu_result))\n",
    "print('Recall: ', recall_score(y_val, pu_result))\n",
    "print('Accuracy: ', accuracy_score(y_val, pu_result))\n",
    "print('F1: ', f1_score(y_val, pu_result))\n",
    "m = confusion_matrix(y_val, pu_result)\n",
    "print('F1 Acc by Class', (m.diagonal()/m.sum(axis=1)))\n",
    "print(confusion_matrix(y_val, pu_result))\n",
    "\n",
    "\n",
    "print('-------- Support to fill the table in the research paper --------')\n",
    "\n",
    "print(\n",
    "      '%.2f'  % (float(accuracy_score(y_val, baseline_result))*100) + '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, baseline_result, average='weighted')*100)+ '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, baseline_result, average=None)[0]*100)+ '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, baseline_result, average=None)[1]*100)+ '\\\\%&',\n",
    "      '%.2f' % matthews_corrcoef(y_val, baseline_result) + '\\\\\\\\',\n",
    "     )\n",
    "\n",
    "print(\n",
    "      '%.2f'  % (float(accuracy_score(y_val, pu_result))*100) + '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, pu_result, average='weighted')*100)+ '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, pu_result, average=None)[0]*100)+ '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, pu_result, average=None)[1]*100)+ '\\\\%&',\n",
    "      '%.2f' % matthews_corrcoef(y_val, pu_result) + '\\\\\\\\',\n",
    "     )\n",
    "\n",
    "print(\n",
    "      '%.2f'  % (float(accuracy_score(y_val, simclr_result))*100) + '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, simclr_result, average='weighted')*100)+ '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, simclr_result, average=None)[0]*100)+ '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, simclr_result, average=None)[1]*100)+ '\\\\%&',\n",
    "      '%.2f' % matthews_corrcoef(y_val, simclr_result) + '\\\\\\\\',\n",
    "     )\n",
    "\n",
    "print(\n",
    "      '%.2f'  % (float(accuracy_score(y_val, siamese_result))*100) + '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, siamese_result, average='weighted')*100)+ '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, siamese_result, average=None)[0]*100)+ '\\\\%&',\n",
    "      '%.2f' % float(f1_score(y_val, siamese_result, average=None)[1]*100)+ '\\\\%&',\n",
    "      '%.2f' % matthews_corrcoef(y_val, siamese_result) + '\\\\\\\\',\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344bfe0e",
   "metadata": {},
   "source": [
    "# End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
